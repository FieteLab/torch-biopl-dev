{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/user/valmiki/bioplnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /om2/user/valmiki/bioplnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 19 17:04:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   0  NVIDIA A100 80G...  On   | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    74W / 300W |   1999MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1356877      C   ...s/pytorch-3.10/bin/python     1997MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "def get_dataloaders(config):\n",
    "    # Load the MNIST dataset\n",
    "    cifar_train = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Load the MNIST test dataset\n",
    "    cifar_test = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=cifar_train,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=cifar_test,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    # Model parameters\n",
    "    num_neurons=100000,\n",
    "    synapses_per_neuron=1000,\n",
    "    num_timesteps=1000,\n",
    "    bias=True,\n",
    "    mm_function=torch.sparse.mm,\n",
    "    # Training parameters\n",
    "    batch_size=32,\n",
    "    optimizer=optim.AdamW,\n",
    "    lr=1e-3,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    log_freq=100,\n",
    "    num_epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorticalSheet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_neurons,\n",
    "        synapses_per_neuron,\n",
    "        bias=True,\n",
    "        mm_function=torch.sparse.mm,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Save the sparse matrix multiplication function\n",
    "        self.mm_function = mm_function\n",
    "\n",
    "        # Create a sparse tensor for the weight matrix\n",
    "        indices = []\n",
    "\n",
    "        # Create adjacency matrix with normal distribution randomized weights\n",
    "        for i in range(num_neurons):\n",
    "            synapses = torch.randint(0, num_neurons, (synapses_per_neuron,))\n",
    "            synapse_root = torch.full_like(synapses, i)\n",
    "            indices.append(torch.stack((synapses, synapse_root)))\n",
    "        indices = torch.cat(indices, dim=1)\n",
    "        values = torch.randn(num_neurons * synapses_per_neuron)\n",
    "\n",
    "        coo_matrix = torch.sparse_coo_tensor(\n",
    "            indices, values, (num_neurons, num_neurons)\n",
    "        )\n",
    "        csr_matrix = coo_matrix.coalesce().to_sparse_csr()\n",
    "        self.weight = nn.Parameter(csr_matrix)\n",
    "\n",
    "        # Initialize the bias vector\n",
    "        self.bias = nn.Parameter(torch.zeros(num_neurons)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform sparse matrix multiplication\n",
    "        output = self.mm_function(self.weight, x)\n",
    "\n",
    "        # Add the bias vector\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class CorticalRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_neurons,\n",
    "        synapses_per_neuron,\n",
    "        num_timesteps,\n",
    "        activation=nn.GELU,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.activation = activation()\n",
    "\n",
    "        # Define the CorticalSheet layer\n",
    "        self.cortical_sheet = CorticalSheet(num_neurons, synapses_per_neuron)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the CorticalSheet layer num_timesteps times\n",
    "        for _ in range(self.num_timesteps):\n",
    "            x = self.activation(self.cortical_sheet(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CorticalRNN(**config).to(device)  # type: ignore\n",
    "    optimizer = config.optimizer(model.parameters(), lr=config.lr)\n",
    "    criterion = config.criterion()\n",
    "    train_loader, test_loader = get_dataloaders(config)\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        bar = tqdm(\n",
    "            train_loader,\n",
    "            desc=(\n",
    "                f\"Training | Epoch: {epoch} | \"\n",
    "                f\"Loss: {0:.4f} | \"\n",
    "                f\"Acc: {0:.2%}\"\n",
    "            ),\n",
    "        )\n",
    "        for i, (images, labels) in enumerate(bar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_correct += correct\n",
    "            running_correct += correct\n",
    "            train_total += len(labels)\n",
    "            running_total += len(labels)\n",
    "\n",
    "            # Log statistics\n",
    "            if (i + 1) % config.log_freq == 0:\n",
    "                running_loss /= config.log_freq\n",
    "                acc = running_correct / running_total\n",
    "                # if config.log_wandb:\n",
    "                #     wandb.log(dict(\n",
    "                #         running_train_loss = running_loss,\n",
    "                #         running_train_acc = running_acc)\n",
    "                #     )\n",
    "                bar.set_description(\n",
    "                    f\"Training | Epoch: {epoch} | \"\n",
    "                    f\"Loss: {running_loss:.4f} | \"\n",
    "                    f\"Acc: {acc:.2%}\"\n",
    "                )\n",
    "                running_loss = 0\n",
    "                running_correct = 0\n",
    "                running_total = 0\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # if config.log_wandb:\n",
    "        #     wandb.log(dict(\n",
    "        #         train_loss = train_loss,\n",
    "        #         train_acc = train_acc)\n",
    "        #     )\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Update statistics\n",
    "                test_loss += loss.item()\n",
    "                predicted = outputs.argmax(-1)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                test_correct += correct\n",
    "                test_total += len(labels)\n",
    "\n",
    "        # Calculate average test loss and accuracy\n",
    "        test_loss /= len(train_loader)\n",
    "        test_acc = test_correct / test_total\n",
    "\n",
    "        # if config.log_wandb:\n",
    "        #     wandb.log(dict(\n",
    "        #         test_loss = test_loss,\n",
    "        #         test_acc = test_acc)\n",
    "        #     )\n",
    "\n",
    "        # Print the epoch statistics\n",
    "        print(\n",
    "            f\"Epoch [{epoch}/{config.num_epochs}] | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Train Accuracy: {train_acc:.2%} | \"\n",
    "            f\"Test Loss: {test_loss:.4f}, \"\n",
    "            f\"Test Accuracy: {test_acc:.2%}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 11075698.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 0/1563 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix, got 4-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     27\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[32], line 64\u001b[0m, in \u001b[0;36mCorticalRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Pass the input through the CorticalSheet layer num_timesteps times\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps):\n\u001b[0;32m---> 64\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcortical_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[32], line 36\u001b[0m, in \u001b[0;36mCorticalSheet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Perform sparse matrix multiplication\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Add the bias vector\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat2 must be a matrix, got 4-D tensor"
     ]
    }
   ],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
