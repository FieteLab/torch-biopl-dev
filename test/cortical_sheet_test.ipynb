{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/user/valmiki/bioplnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /om2/user/valmiki/bioplnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  4 18:01:31 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    52W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "\n",
    "def print_mem_stats():\n",
    "    f, t = torch.cuda.mem_get_info()\n",
    "    print(f\"Free/Total: {f/(1024**3):.2f}GB/{t/(1024**3):.2f}GB\")\n",
    "\n",
    "\n",
    "def get_dataloaders(config):\n",
    "    # Load the MNIST dataset\n",
    "    mnist_train = MNIST(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Load the MNIST test dataset\n",
    "    mnist_test = MNIST(\n",
    "        root=\"./data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=mnist_train,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=mnist_test,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    # Model parameters\n",
    "    num_neurons=10000,\n",
    "    synapses_per_neuron=100,\n",
    "    num_timesteps=100,\n",
    "    sheet_bias=True,\n",
    "    sheet_mm_function=torch.sparse.mm,\n",
    "    sheet_addmm_function=torch.sparse.addmm,\n",
    "    sheet_batch_first=False,\n",
    "    model_dir=\"models\",\n",
    "    # Training parameters\n",
    "    batch_size=16,\n",
    "    optimizer=optim.SGD,\n",
    "    lr=1e-3,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    log_freq=10,\n",
    "    num_epochs=30,\n",
    "    log_wandb=True\n",
    ")\n",
    "try:\n",
    "    os.mkdir(config.model_dir) # type: ignore\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorticalSheet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_neurons,\n",
    "        synapses_per_neuron,\n",
    "        bias=True,\n",
    "        mm_function=torch.sparse.mm,\n",
    "        addmm_function=torch.sparse.addmm,\n",
    "        batch_first=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Save the sparse matrix multiplication function\n",
    "        self.mm_function = mm_function\n",
    "        self.addmm_function = addmm_function\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        # Create a sparse tensor for the weight matrix\n",
    "        indices = []\n",
    "\n",
    "        # Create adjacency matrix with normal distribution randomized weights\n",
    "        for i in range(num_neurons):\n",
    "            synapses = torch.randint(0, num_neurons, (synapses_per_neuron,))\n",
    "            synapse_root = torch.full_like(synapses, i)\n",
    "            indices.append(torch.stack((synapses, synapse_root)))\n",
    "        indices = torch.cat(indices, dim=1)\n",
    "        # Xavier initialization of values (synapses_per_neuron is the fan-in/out)\n",
    "        values = torch.randn(num_neurons * synapses_per_neuron) * math.sqrt(\n",
    "            1 / synapses_per_neuron\n",
    "        )\n",
    "\n",
    "        coo_matrix = torch.sparse_coo_tensor(\n",
    "            indices, values, (num_neurons, num_neurons)\n",
    "        ).coalesce()\n",
    "        self.weight = nn.Parameter(coo_matrix)\n",
    "        # csr_matrix = coo_matrix.coalesce().to_sparse_csr()\n",
    "        # self.weight = nn.Parameter(csr_matrix)\n",
    "\n",
    "        # Initialize the bias vector\n",
    "        self.bias = nn.Parameter(torch.zeros(num_neurons, 1)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: Dense (strided) tensor of shape (batch_size, num_neurons) if\n",
    "        # batch_first, otherwise (num_neurons, batch_size)\n",
    "\n",
    "        # Transpose input if batch_first\n",
    "        if self.batch_first:\n",
    "            x = x.t()\n",
    "        # Perform sparse matrix multiplication with or without bias\n",
    "        if self.bias is not None:\n",
    "            x = self.addmm_function(self.bias, self.weight, x)\n",
    "        else:\n",
    "            x = self.mm_function(self.weight, x)\n",
    "\n",
    "        # Transpose output back to batch first\n",
    "        if self.batch_first:\n",
    "            x = x.t()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CorticalRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_neurons,\n",
    "        synapses_per_neuron,\n",
    "        num_timesteps,\n",
    "        activation=nn.GELU,\n",
    "        sheet_bias=True,\n",
    "        sheet_mm_function=torch.sparse.mm,\n",
    "        sheet_addmm_function=torch.sparse.addmm,\n",
    "        sheet_batch_first=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.activation = activation()\n",
    "        self.sheet_batch_first = sheet_batch_first\n",
    "\n",
    "        # Create the CorticalSheet layer\n",
    "        self.cortical_sheet = CorticalSheet(\n",
    "            num_neurons,\n",
    "            synapses_per_neuron,\n",
    "            sheet_bias,\n",
    "            sheet_mm_function,\n",
    "            sheet_addmm_function,\n",
    "            sheet_batch_first,\n",
    "        )\n",
    "\n",
    "        # Create output block\n",
    "        self.out_block = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 64), activation(), nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: Dense (strided) tensor of shape (batch_size, 1, 32, 32)\n",
    "\n",
    "        # Flatten spatial and channel dimensions\n",
    "        x = x.flatten(1)\n",
    "        # Pad with zeros for rest of neurons\n",
    "        x = F.pad(x, (0, self.num_neurons - x.shape[1]))\n",
    "\n",
    "        # To avoid tranposing x before and after every iteration, we tranpose\n",
    "        # before and after ALL iterations and do not tranpose within forward()\n",
    "        # of self.cortical_sheet\n",
    "        if not self.sheet_batch_first:\n",
    "            x = x.t()\n",
    "\n",
    "        # Pass the input through the CorticalSheet layer num_timesteps times\n",
    "        for _ in range(self.num_timesteps):\n",
    "            x = self.activation(self.cortical_sheet(x))\n",
    "\n",
    "        # Transpose back\n",
    "        if not self.sheet_batch_first:\n",
    "            x = x.t()\n",
    "\n",
    "        # Extract output from last 28*28 neurons (can be arbitrarily large number of neurons)\n",
    "        x = x[:, -28 * 28 :]\n",
    "\n",
    "        # Return classification from out_block\n",
    "        return self.out_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CorticalRNN(**config).to(device)  # type: ignore\n",
    "    optimizer = config.optimizer(model.parameters(), lr=config.lr)\n",
    "    criterion = config.criterion()\n",
    "    train_loader, test_loader = get_dataloaders(config)\n",
    "    \n",
    "    if config.log_wandb:\n",
    "        wandb.init(\n",
    "            project=\"Cortical RNN\", \n",
    "            config=config\n",
    "        )\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        bar = tqdm(\n",
    "            train_loader,\n",
    "            desc=(\n",
    "                f\"Training | Epoch: {epoch} | \"\n",
    "                f\"Loss: {0:.4f} | \"\n",
    "                f\"Acc: {0:.2%}\"\n",
    "            ),\n",
    "        )\n",
    "        for i, (images, labels) in enumerate(bar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_correct += correct\n",
    "            running_correct += correct\n",
    "            train_total += len(labels)\n",
    "            running_total += len(labels)\n",
    "\n",
    "            # Log statistics\n",
    "            if (i + 1) % config.log_freq == 0:\n",
    "                running_loss /= config.log_freq\n",
    "                running_acc = running_correct / running_total\n",
    "                if config.log_wandb:\n",
    "                    wandb.log(dict(\n",
    "                        running_loss = running_loss,\n",
    "                        running_acc = running_acc)\n",
    "                    )\n",
    "                bar.set_description(\n",
    "                    f\"Training | Epoch: {epoch} | \"\n",
    "                    f\"Loss: {running_loss:.4f} | \"\n",
    "                    f\"Acc: {running_acc:.2%}\"\n",
    "                )\n",
    "                running_loss = 0\n",
    "                running_correct = 0\n",
    "                running_total = 0\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        if config.log_wandb:\n",
    "            wandb.log(dict(\n",
    "                train_loss = train_loss,\n",
    "                train_acc = train_acc)\n",
    "            )\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Update statistics\n",
    "                test_loss += loss.item()\n",
    "                predicted = outputs.argmax(-1)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                test_correct += correct\n",
    "                test_total += len(labels)\n",
    "\n",
    "        # Calculate average test loss and accuracy\n",
    "        test_loss /= len(train_loader)\n",
    "        test_acc = test_correct / test_total\n",
    "\n",
    "        if config.log_wandb:\n",
    "            wandb.log(dict(\n",
    "                test_loss = test_loss,\n",
    "                test_acc = test_acc)\n",
    "            )\n",
    "\n",
    "        # Print the epoch statistics\n",
    "        print(\n",
    "            f\"Epoch [{epoch}/{config.num_epochs}] | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Train Accuracy: {train_acc:.2%} | \"\n",
    "            f\"Test Loss: {test_loss:.4f}, \"\n",
    "            f\"Test Accuracy: {test_acc:.2%}\"\n",
    "        )\n",
    "        \n",
    "        # Save Model\n",
    "        # Save Model\n",
    "        file_path = os.path.abspath(os.path.join(config.model_dir, f'model_{epoch}.pt'))\n",
    "        link_path = os.path.abspath(os.path.join(config.model_dir, 'model.pt'))\n",
    "        torch.save(model, file_path)\n",
    "        try:\n",
    "            os.remove(link_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        os.symlink(file_path, link_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free/Total: 46.57GB/79.21GB\n"
     ]
    }
   ],
   "source": [
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gpa8rlz2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d642d1653743d9b86ce75b8c4d4ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.021 MB of 0.021 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>running_acc</td><td>▁</td></tr><tr><td>running_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>running_acc</td><td>0.09375</td></tr><tr><td>running_loss</td><td>2.3082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-haze-2</strong> at: <a href='https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN/runs/gpa8rlz2' target=\"_blank\">https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN/runs/gpa8rlz2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240104_180220-gpa8rlz2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gpa8rlz2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3883cdf12944408f88f230b425e3fc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111943867419743, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rdma/vast-rdma/user/valmiki/bioplnn/wandb/run-20240104_180300-kalm6sbw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN/runs/kalm6sbw' target=\"_blank\">northern-surf-3</a></strong> to <a href='https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN' target=\"_blank\">https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN/runs/kalm6sbw' target=\"_blank\">https://wandb.ai/valmiki-kothare-vk/Cortical%20RNN/runs/kalm6sbw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 0 | Loss: 2.2931 | Acc: 11.25%:  44%|████▍     | 1661/3750 [15:26<19:26,  1.79it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://127.0.0.1:2141/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
