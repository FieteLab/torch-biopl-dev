# Data and Model parameters
model:
  input_size: [64, 64]
  input_dim: 3
  h_pyr_dim: [16, 32, 64, 64]
  h_inter_dims: # Null
  - [4]
  - [8]
  - [16]
  - [16]
  fb_dim: [16, 32, 64, 64]
  inter_mode: same
  exc_kernel_size: 
  - [5, 5]
  - [5, 5]
  - [3, 3]
  - [3, 3]
  inh_kernel_size: 
  - [5, 5]
  - [5, 5]
  - [3, 3]
  - [3, 3]
  num_compartments: 1
  immediate_inhibition: True
  num_layers: 4
  num_steps: 10
  num_classes: 10
  lrp: False
  lrp_input: hidden
  lrp_apply_timestep: 0
  lrp_init_scale: 0.01
  agm: True
  agm_input: layer_output
  agm_apply_timestep: all
  exc_rectify: Null
  inh_rectify: neg
  flush_hidden: False
  hidden_init_mode: zeros
  fb_init_mode: zeros
  out_init_mode: zeros
  fb_adjacency: # Null
  - [0, 0, 0, 0]
  - [1, 0, 0, 0]
  - [0, 1, 0, 0]
  - [0, 0, 1, 0]
  pool_kernel_size: [5, 5]
  pool_stride: [2, 2]
  bias: True
  activation: tanh
  fc_dim: 256
# Training parameters
data:
  root: data/CLEVR_v1.0
  cues_path: data/CLEVR_v1.0/cues
  batch_size: 256
  val_batch_size: 64
  num_train_images: Null
  num_val_images: Null
  holdout: []
  mode: every
  num_workers: 8
optimizer: 
  fn: adamw
  lr: 0.001
  momentum: 0.9
  beta1: 0.9
  beta2: 0.999
scheduler:
  fn: one_cycle
  pct_start: 0.3
criterion: ce
compile:
  disable: True
  fullgraph: True
  dynamic: Null
  backend: inductor
  mode: reduce-overhead
train:
  matmul_precision: high
  epochs: 100
  log_freq: 5
  checkpoint_dir: checkpoints/ei
  grad_clip:
    disable: True
    type: norm
    value: 1.0
seed: Null
tqdm: True
wandb: True