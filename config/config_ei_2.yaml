# Data and Model parameters
model:
  input_size: [128, 128]
  input_dim: 3
  h_pyr_dim: [16, 32, 64, 64]
  h_inter_dims: # Null
  - [4]
  - [8]
  - [16]
  - [16]
  fb_dim: [16, 32, 64, 64]
  inter_mode: same
  exc_kernel_size: 
  - [5, 5]
  - [5, 5]
  - [3, 3]
  - [3, 3]
  inh_kernel_size: 
  - [5, 5]
  - [5, 5]
  - [3, 3]
  - [3, 3]
  num_compartments: 1
  immediate_inhibition: True
  num_layers: 4
  num_steps: 5
  num_classes: 10
  modulation: True
  modulation_type: lr
  modulation_on: layer_output
  modulation_timestep: all
  pertubation: False
  pertubation_type: lr
  pertubation_on: hidden
  pertubation_timestep: 0
  layer_time_delay: False
  exc_rectify: Null
  inh_rectify: pos
  flush_hidden: True
  hidden_init_mode: zeros
  fb_init_mode: zeros
  out_init_mode: zeros
  fb_adjacency: Null
  # - [0, 0, 0, 0]
  # - [1, 0, 0, 0]
  # - [0, 1, 0, 0]
  # - [0, 0, 1, 0]
  pool_kernel_size: [5, 5]
  pool_stride: [2, 2]
  bias: True
  pre_inh_activation: tanh
  post_inh_activation: Null
  fc_dim: 256
# Training parameters
data:
  root: data/CLEVR_v1.0
  cues_path: data/CLEVR_v1.0/cues
  batch_size: 256
  val_batch_size: 64
  num_train_images: Null
  num_val_images: Null
  holdout: []
  mode: every
  num_workers: 8
optimizer: 
  fn: adamw
  lr: 0.0004
  momentum: 0.9
  beta1: 0.9
  beta2: 0.999
scheduler:
  fn: one_cycle
  pct_start: 0.3
criterion: ce
compile:
  disable: True
  fullgraph: True
  dynamic: Null
  backend: inductor
  mode: reduce-overhead
train:
  matmul_precision: high
  epochs: 100
  log_freq: 5
  checkpoint_root: checkpoints/ei
  grad_clip:
    disable: True
    type: norm
    value: 1.0
seed: Null
tqdm: True
wandb: True