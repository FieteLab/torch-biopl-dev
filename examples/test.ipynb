{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/user/valmiki/bioplnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /om2/user/valmiki/bioplnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transforms' from 'torch.utils.data' (/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch/utils/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'transforms' from 'torch.utils.data' (/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch/utils/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy\n",
    "import os\n",
    "from bioplnn.dataset import CIFAR10_V1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bioplnn.dataset.CIFAR10_V1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor()])\n",
    "        input_dim = 1\n",
    "trainset = CIFAR10_V1(root='./data', train=True, retina_path=\"connection\",\n",
    "                                    download=True, transform=transform, mode=args.mode,\n",
    "                                    dual_hemisphere=args.dual_hemisphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvRNN(nn.Module):\n",
    "    def __init__(self, input_size, kernel_size):\n",
    "        super(ConvRNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_size, input_size, kernel_size, padding=1)\n",
    "        self.conv.register_full_backward_hook(lambda _, __, ___: print(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _ in range(10):\n",
    "            x = F.relu(self.conv(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 3\n",
    "kernel_size = 3\n",
    "height = 32\n",
    "width = 32\n",
    "\n",
    "model = ConvRNN(input_size, kernel_size)\n",
    "input_data = torch.randn(16, input_size, height, width)\n",
    "output = model(input_data)\n",
    "loss = output.sum()\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(16, 3, 32, 32, requires_grad=True)\n",
    "conv = torch.nn.Conv2d(3, 3, 3, padding=1)\n",
    "conv.weight.register_hook(lambda grad: print(1))\n",
    "for _ in range(10):\n",
    "    x = F.relu(conv(x))\n",
    "loss = x.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_graph(path):\n",
    "    connection = {}\n",
    "    coordinates = []\n",
    "    Nunits = []\n",
    "    Adj = []\n",
    "    weight_path = glob.glob(os.path.join(path, '*.npz'))[0]\n",
    "    sparse_connection = scipy.sparse.load_npz(weight_path)\n",
    "    mask_path = glob.glob(os.path.join(path, '*.npy'))\n",
    "    if len(mask_path) == 1:\n",
    "        masks = np.load(mask_path[0])\n",
    "        layers = [np.stack(mask.nonzero()) for mask in masks[:-1]]\n",
    "        Ny = masks.shape[2]\n",
    "    else:\n",
    "        layers = ['V1_indices', 'V2_indices', 'V3_indices', 'V4_indices']\n",
    "        layers = [np.load(os.path.join(path, f'{layer}.npy')) for layer in layers]\n",
    "        Ny = 300\n",
    "    \n",
    "    for coor in layers:\n",
    "        coordinates.append(coor[0] * Ny + coor[1])\n",
    "\n",
    "    for i, incoming in enumerate(coordinates[:-1]):\n",
    "        adj = torch.from_numpy(sparse_connection[coordinates[i+1]][:, incoming].toarray()).float()\n",
    "        Adj.append(adj)\n",
    "\n",
    "    return Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"connection\"\n",
    "weight_path = glob.glob(os.path.join(path, '*.npz'))[0]\n",
    "sparse_connection = scipy.sparse.load_npz(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['V1_indices', 'V2_indices', 'V3_indices', 'V4_indices']\n",
    "layers = [np.load(os.path.join(path, f'{layer}.npy')) for layer in layers]\n",
    "Ny = 300\n",
    "\n",
    "coordinates = []\n",
    "for coor in layers:\n",
    "    coordinates.append(coor[0] * Ny + coor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = build_graph(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_connection = scipy.sparse.load_npz(weight_path).tocoo()\n",
    "values = torch.randn_like(torch.tensor(sparse_connection.data))\n",
    "indices = torch.tensor(np.vstack((sparse_connection.row, sparse_connection.col)))\n",
    "weight = torch.sparse_coo_tensor(indices, values, sparse_connection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['V1_indices', 'V2_indices', 'V3_indices', 'V4_indices']\n",
    "coordinates = [np.load(os.path.join(path, f'{layer}.npy')) for layer in layers]\n",
    "Ny = 300\n",
    "for coor, layer in zip(coordinates, layers):\n",
    "    coor = torch.tensor(coor[0] * Ny + coor[1])\n",
    "    torch.save(coor, os.path.join(path, f'{layer}.pt'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_connection = torch.sparse_coo_tensor(indices, values, sparse_connection.shape).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates1d = [torch.tensor(coor[0] * Ny + coor[1]) for coor in coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates1d[3].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35, dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates[3].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
