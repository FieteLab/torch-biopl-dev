{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchode as to\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from bioplnn.utils import AttrDict, initialize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 14 18:30:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:83:00.0 Off |                    0 |\n",
      "| N/A   39C    P0             53W /  300W |       3MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling solver with kwargs: {'mode': 'max-autotune', 'dynamic': False, 'fullgraph': True}\n",
      "HH sparsity 0.20%\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"config/\", job_name=\"testing\"):\n",
    "    config = compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\"data=mnist_conn\", \"model=conn\"],\n",
    "    )\n",
    "config = OmegaConf.to_container(config, resolve=True)\n",
    "config = AttrDict(config)\n",
    "\n",
    "model = initialize_model(**config.model)\n",
    "rnn = model.rnn\n",
    "print(\n",
    "    f\"HH sparsity {rnn.hh.values.shape[0] / (rnn.hh.in_features * rnn.hh.out_features):.2%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sunny_root = \"/om/user/sunnyd/dros-vision/\"\n",
    "neuron_ids = pd.read_csv(sunny_root + \"visual_neuron_ids.csv\")\n",
    "num_neurons = len(neuron_ids)\n",
    "input_neuron_ids = pd.read_csv(sunny_root + \"visual_column_assignment.csv\")\n",
    "num_input_neurons = len(input_neuron_ids)\n",
    "column_data = torch.tensor(\n",
    "    np.load(sunny_root + \"moving_mnist_vision.npy\"), dtype=torch.float32\n",
    ")\n",
    "lookup = dict(zip(neuron_ids[\"root_id\"].to_list(), neuron_ids.index))\n",
    "input_projection = np.eye(num_neurons)[\n",
    "    :, input_neuron_ids[\"root_id\"].map(lookup).to_numpy()\n",
    "]\n",
    "column_ids = input_neuron_ids[\"column_ids\"] - 1\n",
    "input_indices = torch.tensor(input_neuron_ids[\"root_id\"].map(lookup))\n",
    "column_ids = torch.tensor(input_neuron_ids[\"column_ids\"] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_connectivity():\n",
    "    connectivity_hh = np.load(sunny_root + \"visual_adj_matrix_20240711.npy\")\n",
    "    connectivity_hh = torch.tensor(connectivity_hh).to_sparse_coo().coalesce()\n",
    "\n",
    "    # Load connectivity_ih\n",
    "    indices_ih = torch.stack(\n",
    "        (\n",
    "            input_indices,\n",
    "            torch.arange(input_neuron_ids.shape[0]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    values_ih = torch.ones(indices_ih.shape[1])\n",
    "\n",
    "    connectivity_ih = torch.sparse_coo_tensor(\n",
    "        indices_ih,\n",
    "        values_ih,\n",
    "        (num_neurons, num_input_neurons),\n",
    "        check_invariants=True,\n",
    "    ).coalesce()\n",
    "\n",
    "    # Save connectivity\n",
    "    torch.save(connectivity_hh, config.model.rnn_kwargs.connectivity_hh)  # type: ignore\n",
    "    torch.save(connectivity_ih, config.model.rnn_kwargs.connectivity_ih)  # type: ignore\n",
    "\n",
    "    # Save input indices\n",
    "    torch.save(input_indices, config.model.rnn_kwargs.input_indices)  # type: ignore\n",
    "\n",
    "\n",
    "# save_connectivity()\n",
    "# connectivity_hh = torch.load(\n",
    "#     config.model.rnn_kwargs.connectivity_hh, weights_only=True\n",
    "# )\n",
    "# connectivity_ih = torch.load(\n",
    "#     config.model.rnn_kwargs.connectivity_ih, weights_only=True\n",
    "# )\n",
    "# input_indices = torch.load(\n",
    "#     config.model.rnn_kwargs.input_indices, weights_only=True\n",
    "# )\n",
    "\n",
    "# pool = torch.nn.AdaptiveMaxPool2d((100, 100))\n",
    "# connectivity = pool(connectivity_hh.unsqueeze(0).to_dense().float())\n",
    "# plt.imshow(\n",
    "#     connectivity.squeeze(0).detach().cpu().numpy(),\n",
    "#     cmap=\"gray\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t: torch.Tensor, y: torch.Tensor, args: dict):\n",
    "    h = y.t()\n",
    "\n",
    "    x = args[\"x\"]\n",
    "    bias = args[\"bias\"]\n",
    "    leak = args[\"leak\"]\n",
    "    column_ids = args[\"column_ids\"]\n",
    "    T = args[\"tau\"]\n",
    "\n",
    "    x_t = x[:, int(t * 10), column_ids].t()\n",
    "\n",
    "    h = 1 / T * (-h * leak + bias + rnn.hh(h) + 10 * rnn.ih(x_t))\n",
    "\n",
    "    return h.t()\n",
    "\n",
    "\n",
    "rnn.forward = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = column_data[:1].to(device)\n",
    "y0 = torch.randn(len(neuron_ids)).unsqueeze(0).to(device)\n",
    "t_eval = torch.linspace(0.0, 1.0, 10).unsqueeze(0).to(device)\n",
    "\n",
    "term = to.ODETerm(f, with_args=True)  # type: ignore\n",
    "step_method = to.Dopri5(term=term)\n",
    "step_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\n",
    "solver = to.AutoDiffAdjoint(\n",
    "    step_method,  # type: ignore\n",
    "    step_size_controller,  # type: ignore\n",
    ").to(device)\n",
    "# solver = to.BacksolveAdjoint(term, step_method, step_size_controller).to(\n",
    "#     device\n",
    "# )\n",
    "# solver = torch.compile(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m torch.cuda.empty_cache()\n\u001b[32m      3\u001b[39m problem = to.InitialValueProblem(y0=y0, t_eval=t_eval)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sol = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleak\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtau\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m ys = sol.ys.transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Plot\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torchode/adjoints.py:103\u001b[39m, in \u001b[36mAutoDiffAdjoint.solve\u001b[39m\u001b[34m(self, problem, term, dt0, args)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Compute an initial step size\u001b[39;00m\n\u001b[32m    102\u001b[39m convergence_order = step_method.convergence_order()\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m dt, controller_state, f0 = \u001b[43mstep_size_controller\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvergence_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m method_state = step_method.init(term, problem, f0, stats=stats, args=args)\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Ensure that the initial dt does not step outside of the time domain\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torchode/step_size_controllers.py:346\u001b[39m, in \u001b[36mIntegralController.init\u001b[39m\u001b[34m(self, term, problem, method_order, dt0, stats, args)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dt0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    345\u001b[39m     dt_max = (problem.t_end - problem.t_start).abs()\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     dt0, f0 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select_initial_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m.\u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime_direction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdt_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    357\u001b[39m     f0 = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torchode/step_size_controllers.py:459\u001b[39m, in \u001b[36mIntegralController._select_initial_step\u001b[39m\u001b[34m(self, term, t0, y0, direction, dt_max, convergence_order, stats, args)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m term \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    458\u001b[39m norm = \u001b[38;5;28mself\u001b[39m.norm\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m f0 = \u001b[43mterm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m error_bounds = torch.add(\u001b[38;5;28mself\u001b[39m.atol, torch.abs(y0), alpha=\u001b[38;5;28mself\u001b[39m.rtol)\n\u001b[32m    462\u001b[39m inv_scale = torch.reciprocal(error_bounds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torchode/terms.py:61\u001b[39m, in \u001b[36mODETerm.vf\u001b[39m\u001b[34m(self, t, y, stats, args)\u001b[39m\n\u001b[32m     58\u001b[39m     n_f_evals.add_(\u001b[32m1\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_args:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f(t, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mf\u001b[39m\u001b[34m(t, y, args)\u001b[39m\n\u001b[32m      8\u001b[39m T = args[\u001b[33m\"\u001b[39m\u001b[33mtau\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m x_t = x[:, \u001b[38;5;28mint\u001b[39m(t * \u001b[32m10\u001b[39m), column_ids].t()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m h = \u001b[32m1\u001b[39m / T * (-h * leak + bias + \u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m + \u001b[32m10\u001b[39m * rnn.ih(x_t))\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m h.t()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rdma/vast-rdma/user/valmiki/bioplnn/src/bioplnn/models/sparse.py:104\u001b[39m, in \u001b[36mSparseLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    100\u001b[39m     x = x.permute(*permutation)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    102\u001b[39m x = x.flatten(start_dim=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m x = \u001b[43mtorch_sparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    113\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bioplnn/lib/python3.12/site-packages/torch_sparse/spmm.py:27\u001b[39m, in \u001b[36mspmm\u001b[39m\u001b[34m(index, value, m, n, matrix)\u001b[39m\n\u001b[32m     24\u001b[39m row, col = index[\u001b[32m0\u001b[39m], index[\u001b[32m1\u001b[39m]\n\u001b[32m     25\u001b[39m matrix = matrix \u001b[38;5;28;01mif\u001b[39;00m matrix.dim() > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m matrix.unsqueeze(-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m out = \u001b[43mmatrix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m out = out * value.unsqueeze(-\u001b[32m1\u001b[39m)\n\u001b[32m     29\u001b[39m out = scatter_add(out, row, dim=-\u001b[32m2\u001b[39m, dim_size=m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# Solve ODE\n",
    "torch.cuda.empty_cache()\n",
    "problem = to.InitialValueProblem(y0=y0, t_eval=t_eval)  # type: ignore\n",
    "sol = solver.solve(\n",
    "    problem,\n",
    "    args={\n",
    "        \"x\": x,\n",
    "        \"bias\": 0.1,\n",
    "        \"leak\": 20.0,\n",
    "        \"tau\": 10.0,\n",
    "        \"column_ids\": column_ids,\n",
    "    },\n",
    ")\n",
    "ys = sol.ys.transpose(0, 1)\n",
    "\n",
    "# Plot\n",
    "plt.plot(\n",
    "    ys.squeeze()[:, torch.randint(0, 47521, (25,))].detach().cpu().numpy()\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: tensor([[-0.0699,  0.3276,  0.0266, -0.5618,  0.2015, -0.3049,  0.2818, -0.3217,\n",
      "          0.0569,  0.1768]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "labels: tensor([[0.7775, 0.3807, 0.2145, 0.4794, 0.3921, 0.4407, 0.5605, 0.6015, 0.2553,\n",
      "         0.6862]], device='cuda:0')\n",
      "preds shape: torch.Size([1, 10])\n",
      "labels shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "preds = model.out_layer(ys[0])\n",
    "labels = torch.rand((1, 10)).to(device)\n",
    "print(f\"preds: {preds}\")\n",
    "print(f\"labels: {labels}\")\n",
    "print(f\"preds shape: {preds.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = torch.nn.CrossEntropyLoss()(preds, labels)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(f\"loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioplnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
