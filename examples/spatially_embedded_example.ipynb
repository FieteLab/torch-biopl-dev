{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic API usage example\n",
    "\n",
    "## Overview\n",
    "\n",
    "The goal of this tutorial is to wire up a simple model that is comprised of a spatially embedded brain area, specify a simple learning objective, and optimize model parameters.\n",
    "\n",
    "Before we begin, here are a few notes pertaining to the nomenclature we have adopted.\n",
    "\n",
    "- A neuron ***class*** is defined by its synaptic affiliation. In `torch-biopl` you can configure types to be `Excitatory`/`Inhibitory` (where synapses have a postive/negative sign), or `Hybrid` which defaults to standard machine learning-style synapses that are unconstrained.\n",
    "- Within each neuron class, you can instantiate neuron ***types***. We employ the definition of neuron types with an eye to be able to specify inter-type local connectivity rules. \n",
    "- Within each neuron type, are ***subtypes***. Neurons within a subtype can (but don't have to) share properties like time constants, nonlinearities, and biases.\n",
    "- Each neural area can be configured independently by specifying its classes, types, subtypes, and inter-type connectivity rules.\n",
    "- Areas can be stitched together to form larger networks.\n",
    "- Learnable parameters in `torch-biopl` are usually the synaptic weights, neural time constants, and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from bioplnn.models import SpatiallyEmbeddedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us wire up a simple one-area network with two neural classes. Let one of them be an `Excitatory` cell class and one be `Inhibitory` each with `16` subtypes. Now, we have our neural populations. All that's left to do is to specify the inter-type connectivity. \n",
    "\n",
    "In `torch-biopl` we adopt the following convention:\n",
    "\n",
    "- Inter-celltype connectivity (within a given area) is specified through an adjacency matrix.\n",
    "- In addition to the cell types within an area, we also have to account for projections into and out of the area. Keeping this in mind, we use a schema where rows in the adjacency matrix represent the ***pre-synaptic*** cell type and columns represent the ***post-synaptic*** cell type. \n",
    "- The **first row** always denotes projections into the area, and the **last column** always denotes feedforward projections out of the area.\n",
    "\n",
    "For example, if our cell_type_1 is E and cell_type_2 is I, then `inter_cell_type_connectivity`=$\\begin{bmatrix}1&1&0\\cr1&1&1\\cr1&1&0\\end{bmatrix}$ represents a standard recurrent inhibitory circuit motif (ala [Wong et al. (2006)](https://pubmed.ncbi.nlm.nih.gov/16436619/)), where both the E and I populations receive input, and only the E population projects downstream.\n",
    "\n",
    "Since we plan to train on grayscale images in this example, `in_channels` = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "model = SpatiallyEmbeddedClassifier(\n",
    "    rnn_kwargs={\n",
    "        \"num_areas\": 1,\n",
    "        \"area_kwargs\": [\n",
    "            {\n",
    "                \"num_cell_types\": 2,\n",
    "                \"num_cell_subtypes\": np.array([16, 16]),\n",
    "                \"cell_type_class\": np.array(['excitatory', 'inhibitory']),\n",
    "                \"inter_cell_type_connectivity\": np.array([[1, 1, 0], [1, 1, 1], [1, 1, 0]]),\n",
    "                \"in_size\": [28, 28],\n",
    "                \"in_channels\": 1,\n",
    "                \"out_channels\": 32,\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    num_classes = 10,\n",
    "    fc_dim = 256,\n",
    "    dropout = 0.5,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch2/weka/mcdermott/lakshmin/conda_envs/test_bioplnn_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dataloader setup\n",
    "transform = T.Compose([T.ToTensor(), T.Normalize((0.1307,), (0.3081,))])\n",
    "train_data = MNIST(root=\"data\", train=True, transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=256, num_workers=8, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 101/235 [00:10<00:06, 21.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 0 | Loss: 230.5550 | Acc: 11.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 202/235 [00:16<00:01, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 0 | Loss: 220.1151 | Acc: 20.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.13it/s]\n",
      " 43%|████▎     | 102/235 [00:10<00:06, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 1 | Loss: 257.5806 | Acc: 26.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 201/235 [00:15<00:01, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 1 | Loss: 180.8878 | Acc: 28.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:16<00:00, 13.97it/s]\n",
      " 43%|████▎     | 102/235 [00:09<00:06, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 2 | Loss: 237.9631 | Acc: 30.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 204/235 [00:14<00:01, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 2 | Loss: 171.1650 | Acc: 32.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:15<00:00, 14.71it/s]\n",
      " 44%|████▍     | 104/235 [00:09<00:06, 21.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 3 | Loss: 222.0076 | Acc: 35.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 204/235 [00:14<00:01, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 3 | Loss: 157.9773 | Acc: 38.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:16<00:00, 14.59it/s]\n",
      " 44%|████▍     | 104/235 [00:09<00:06, 20.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 4 | Loss: 205.7286 | Acc: 40.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 202/235 [00:14<00:01, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 4 | Loss: 148.0692 | Acc: 42.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:15<00:00, 15.02it/s]\n",
      " 45%|████▍     | 105/235 [00:10<00:05, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 5 | Loss: 194.4819 | Acc: 43.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 204/235 [00:14<00:01, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 5 | Loss: 139.6240 | Acc: 45.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:16<00:00, 14.60it/s]\n",
      " 44%|████▍     | 103/235 [00:10<00:06, 20.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 6 | Loss: 186.2790 | Acc: 46.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 202/235 [00:14<00:01, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 6 | Loss: 134.6118 | Acc: 48.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:16<00:00, 14.54it/s]\n",
      " 44%|████▍     | 103/235 [00:09<00:06, 20.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 7 | Loss: 180.0221 | Acc: 48.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 201/235 [00:14<00:01, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 7 | Loss: 131.4528 | Acc: 49.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:16<00:00, 14.62it/s]\n",
      " 44%|████▍     | 103/235 [00:09<00:06, 21.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 8 | Loss: 173.1868 | Acc: 51.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 203/235 [00:14<00:01, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 8 | Loss: 130.3644 | Acc: 49.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:16<00:00, 14.67it/s]\n",
      " 45%|████▍     | 105/235 [00:09<00:05, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 9 | Loss: 171.3067 | Acc: 51.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 204/235 [00:14<00:01, 21.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 9 | Loss: 126.4864 | Acc: 51.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:15<00:00, 15.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the training loop\n",
    "model.train()\n",
    "n_epochs = 10\n",
    "log_frequency = 100\n",
    "\n",
    "running_loss, running_correct, running_total = 0, 0, 0\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (x, labels) in enumerate(tqdm(train_loader)):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        torch._inductor.cudagraph_mark_step_begin()\n",
    "        logits = model(x, num_steps=5)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running accuracy and loss\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        running_total += labels.size(0)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        running_acc = running_correct / running_total\n",
    "        if (i + 1)%log_frequency == 0:\n",
    "            print(\n",
    "                f\"Training | Epoch: {epoch} | \" +\n",
    "                f\"Loss: {running_loss:.4f} | \" +\n",
    "                f\"Acc: {running_acc:.2%}\"\n",
    "            )\n",
    "            running_loss, running_correct, running_total = 0, 0, 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioplnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
