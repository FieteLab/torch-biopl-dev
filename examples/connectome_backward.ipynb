{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing gradients and backpropagating through connectome-initialized models\n",
    "\n",
    "While the previous tutorial showed you how to initialize a neural network with connectome-determined weights, it didn't provide you with information on how to \"tune\" model parameters in a data-driven manner. Turns out, computing (and backpropagating) gradients in networks with both ***sparse and dense*** tensors is non-trivial. In this tutorial, we spin up a small example on how you can accomplish this in `torch-biopl`. \n",
    "\n",
    "Goals:\n",
    "\n",
    "- Continue from our previous example.\n",
    "- Implement a wrapper on top of the `ConnectomeODERNN` to support a readout layer.\n",
    "- Setup a simple training loop.\n",
    "\n",
    "Note: For demonstration purposes, we'll use flattened MNIST images as inputs into the connectome. This is however simplistic and we do allow for arbitrarily complex input mappings. To learn how to do that please refer to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bioplnn.models import ConnectomeODEClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "print('Using device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18448HYpYrm60boziHG73bxN4CK5jG-1g\n",
      "From (redirected): https://drive.google.com/uc?id=18448HYpYrm60boziHG73bxN4CK5jG-1g&confirm=t&uuid=f892a498-2144-4a63-895f-6673118b3557\n",
      "To: /net/vast-storage/scratch/vast/mcdermott/lakshmin/hackathon-test/bioplnn/examples/turaga-dros-visual-connectome.pt\n",
      "100%|█████████████████████████████████████████| 111M/111M [00:00<00:00, 111MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the connectome and read it in as a torch tensor. We have pre-processed this as a sparse tensor for the purposes of this example.\n",
    "!gdown \"https://drive.google.com/uc?id=18448HYpYrm60boziHG73bxN4CK5jG-1g\"\n",
    "connectome = torch.load('turaga-dros-visual-connectome.pt', weights_only=True)\n",
    "\n",
    "from bioplnn.utils.torch import create_identity_ih_connectivity\n",
    "# since we are feeding in MNIST images\n",
    "input_size = 28 * 28 \n",
    "num_neurons = connectome.shape[0]\n",
    "\n",
    "input_projection_matrix = create_identity_ih_connectivity(\n",
    "                                input_size=input_size,\n",
    "                                num_neurons=num_neurons,\n",
    "                                input_indices=torch.randint(high=num_neurons, size=(input_size,))\n",
    "                            )\n",
    "\n",
    "# for now, lets just read outputs from all neurons\n",
    "output_projection_matrix = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the classifier wrapper\n",
    "\n",
    "Here, we have written a simple utility that adds an output projecting layer from the connectome to the desired logit space. Again, this is simply an example. Please feel free to add sophistication to this as you please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SparseRNN.__init__() got an unexpected keyword argument 'compile_solver_kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mConnectomeODEClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhidden_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neurons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnectivity_hh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnectome\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnectivity_ih\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_projection_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_neurons\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_projection_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnonlinearity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSigmoid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_first\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompile_solver_kwargs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax-autotune\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdynamic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfullgraph\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfc_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m.to(device)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Define the optimizer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/vast-storage/scratch/vast/mcdermott/lakshmin/hackathon-test/bioplnn/src/bioplnn/models/classifiers.py:121\u001b[39m, in \u001b[36mConnectomeODEClassifier.__init__\u001b[39m\u001b[34m(self, rnn_kwargs, num_classes, fc_dim, dropout)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m     rnn_kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m     dropout: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.2\u001b[39m,\n\u001b[32m    118\u001b[39m ):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28mself\u001b[39m.rnn = \u001b[43mConnectomeODERNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrnn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rnn.output_neurons \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m         out_size = \u001b[38;5;28mself\u001b[39m.rnn.hidden_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/vast-storage/scratch/vast/mcdermott/lakshmin/hackathon-test/bioplnn/src/bioplnn/models/connectome.py:65\u001b[39m, in \u001b[36mConnectomeRNNMixIn.__init__\u001b[39m\u001b[34m(self, output_neurons, num_neuron_types, neuron_type_class, neuron_type_indices, neuron_type_nonlinearity, neuron_type_tau_init, default_tau_init_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ConnectomeODERNN)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSparseODERNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.output_neurons = \u001b[38;5;28mself\u001b[39m._init_output_neurons(output_neurons)\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Neuron type parameters\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: SparseRNN.__init__() got an unexpected keyword argument 'compile_solver_kwargs'"
     ]
    }
   ],
   "source": [
    "model = ConnectomeODEClassifier(\n",
    "    rnn_kwargs={\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": num_neurons,\n",
    "        \"connectivity_hh\": torch.abs(connectome),\n",
    "        \"connectivity_ih\": input_projection_matrix,\n",
    "        \"output_neurons\": output_projection_matrix,\n",
    "        \"nonlinearity\": \"Sigmoid\",\n",
    "        \"batch_first\": False,\n",
    "        \"compile_solver_kwargs\": {\n",
    "            \"mode\": \"max-autotune\",\n",
    "            \"dynamic\": False,\n",
    "            \"fullgraph\": True,\n",
    "        },\n",
    "    },\n",
    "    num_classes = 10,\n",
    "    fc_dim = 256,\n",
    "    dropout = 0.5,\n",
    ").to(device)\n",
    "print(model)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader setup\n",
    "transform = T.Compose([T.ToTensor(), T.Normalize((0.1307,), (0.3081,))])\n",
    "train_data = MNIST(root=\"data\", train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=128, num_workers=0, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "# print training statistics every five batches\n",
    "log_frequency = 50\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Things to look out for\n",
    "\n",
    "- Depending on the GPU you have access to and the number of CPUs you will have to adjust `batch_size` and `num_workers` in the DataLoader, as well as `num_steps` in the model forward pass. For reference, on a A100 GPU and a single CPU `batch_size = 256`, `num_workers = 0`, and `num_steps=5` is a reasonable estimate.\n",
    "- In this example, we have used the torch compiler with the `max-autotune` flag. This means the first few steps in the first epoch WILL BE EXTREMELY SLOW. But, this will dramatically improve as the training goes on. Fret not, early on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 0 | Loss: 198.0978 | Acc: 10.83%\n",
      "Training | Epoch: 0 | Loss: 115.1342 | Acc: 9.59%\n",
      "Training | Epoch: 0 | Loss: 115.1375 | Acc: 10.36%\n",
      "Training | Epoch: 0 | Loss: 115.5774 | Acc: 10.39%\n",
      "Training | Epoch: 0 | Loss: 115.0750 | Acc: 10.95%\n",
      "Training | Epoch: 0 | Loss: 115.1287 | Acc: 10.41%\n",
      "Training | Epoch: 0 | Loss: 115.0829 | Acc: 10.66%\n",
      "Training | Epoch: 0 | Loss: 115.0965 | Acc: 10.14%\n",
      "Training | Epoch: 0 | Loss: 115.0782 | Acc: 11.25%\n",
      "Training | Epoch: 1 | Loss: 158.7733 | Acc: 11.64%\n",
      "Training | Epoch: 1 | Loss: 115.0757 | Acc: 11.41%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m _, predicted = torch.max(logits, \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m running_total += labels.size(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m running_correct += \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m running_loss += loss.item()\n\u001b[32m     20\u001b[39m running_acc = running_correct / running_total\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "running_loss, running_correct, running_total = 0, 0, 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (x, labels) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        torch._inductor.cudagraph_mark_step_begin()\n",
    "        logits = model(x, num_steps=2)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running accuracy and loss\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        running_total += labels.size(0)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        running_acc = running_correct / running_total\n",
    "        if (i + 1)%log_frequency == 0:\n",
    "            print(\n",
    "                f\"Training | Epoch: {epoch} | \" +\n",
    "                f\"Loss: {running_loss:.4f} | \" +\n",
    "                f\"Acc: {running_acc:.2%}\"\n",
    "            )\n",
    "            running_loss, running_correct, running_total = 0, 0, 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioplnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
