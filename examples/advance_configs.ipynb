{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring advanced configurations\n",
    "\n",
    "## Overview\n",
    "\n",
    "In addition to the essential capabilities exposed in the first tutorial, we can exercise fine-grained control in how we wire up biologically-plausible networks. These are some of the functionality we will explore in this section:\n",
    "\n",
    "- Synapse vs neuron nonlinearities\n",
    "- Microcircuit archetypes\n",
    "- Parameter sharing capabilities\n",
    "- Hierarchically constructed neural areas\n",
    "- Inter-areal feedback connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from bioplnn.models import SpatiallyEmbeddedRNN, SpatiallyEmbeddedAreaConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synapse vs neuron nonlinearities\n",
    "\n",
    "What do we mean by this? In an attempt to distinguish synaptic transfer functions from post-aggregation neuronal transfer functions, we give users the ability to specify pre- and post-integration nonlinearities. \n",
    "\n",
    "Let us consider the same example model from the previous tutorial: A simple one-area network with two neural classes with the following `inter_neuron_type_connectivity`: $\\begin{bmatrix}1&1&0\\cr1&1&1\\cr1&1&0\\end{bmatrix}$. Following the same convention as the connectivity matrix, you can specify the transfer function for each of those synapse groups by setting the `inter_neuron_type_nonlinearity` parameter. Similarly, `neuron_type_nonlinearity` can be used to control the post-aggregation transfer function for each neuron type.\n",
    "\n",
    "If you were to construe a scenario where synapses have unbounded transfer functions while the neuron as whole is bounded from above (and for the sake of argument: bounded differently for the E and I subpopulations), then you'd do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a custom activation function that works similarly to a ReLU but is bounded from above!\n",
    "from torch.nn.modules.activation import Hardtanh\n",
    "\n",
    "\n",
    "class ModRelu(Hardtanh):\n",
    "    def __init__(self, _ub: float, _lb: float = 0.0, inplace: bool = False):\n",
    "        super().__init__(_lb, _ub, inplace)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        inplace_str = \"inplace=True\" if self.inplace else \"\"\n",
    "        return inplace_str\n",
    "\n",
    "\n",
    "upper_bounded_relu = ModRelu(_ub=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "        num_neuron_types=2,\n",
    "        num_neuron_subtypes=np.array([16, 16]),\n",
    "        neuron_type_class=np.array([\"excitatory\", \"inhibitory\"]),\n",
    "        neuron_type_nonlinearity=[\"sigmoid\", upper_bounded_relu],\n",
    "        inter_neuron_type_connectivity=np.array(\n",
    "            [[1, 1, 0], [1, 1, 1], [1, 1, 0]]\n",
    "        ),\n",
    "        inter_neuron_type_nonlinearity=np.array(\n",
    "            [\n",
    "                [\"relu\", \"relu\", \"\"],\n",
    "                [\"relu\", \"relu\", \"relu\"],\n",
    "                [\"relu\", \"relu\", \"\"],\n",
    "            ]\n",
    "        ),\n",
    "        in_size=[28, 28],\n",
    "        in_channels=1,\n",
    "        out_channels=32,\n",
    "    )\n",
    "]\n",
    "model = SpatiallyEmbeddedRNN(\n",
    "    num_areas=1, area_configs=area_configs, batch_first=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microcircuit archetypes\n",
    "\n",
    "It must be evident that `inter_neuron_type_connectivity` is a powerful option that can be used to dictate a wide variety of microcircuit motifs. We provide some examples below for inspiration.\n",
    "\n",
    "#### Feedback inhibition\n",
    "Parvalbumin-positive inhibitory cells in Layer 2/3 of the cortex are known to interact with Pyramidal cells through some form of divisive inhibition [Jonke et al. (2017)](https://www.jneurosci.org/content/37/35/8511). To instantiate this microcircuit, you'd set `inter_neuron_type_connectivity` $= \\begin{bmatrix}1&0&0\\cr0&1&1\\cr1&1&0\\end{bmatrix}$ (conventions same as in the original example).\n",
    "\n",
    "#### Feedforward inhibition\n",
    "Feedforward inhibition is another essential mechanism within the brain, to regulate neuronal firing and prevent runaway excitation ([Panthi and Leitch (2019)](https://pubmed.ncbi.nlm.nih.gov/31494287/), [Large et al. (2016)](https://pmc.ncbi.nlm.nih.gov/articles/PMC4776521/)). To implement the microcircuit presented in these (and related) papers, you can set `inter_neuron_type_connectivity` $= \\begin{bmatrix}1&1&0\\cr1&0&1\\cr1&1&1\\end{bmatrix}$\n",
    "\n",
    "#### Pyr-PV-SST-VIP motif\n",
    "Interneuron subtypes play a critical role in several aspects of cortical function ([Guo and Kumar (2023)](https://www.nature.com/articles/s42003-023-05231-0), [Condylis et al. (2022)](https://www.science.org/doi/10.1126/science.abl5981), etc.). Of particular interest is a motif that involves one excitatory and three inhibitory interneuron populations (PV, SST, VIP). Please refer to these papers for pictorial depictions of the microcircuits. To realise this in `torch-biopl`, we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "        num_neuron_types=4,\n",
    "        num_neuron_subtypes=np.array([16, 8, 8, 8]),\n",
    "        neuron_type_class=np.array(\n",
    "            [\"excitatory\", \"inhibitory\", \"inhibitory\", \"inhibitory\"]\n",
    "        ),\n",
    "        inter_neuron_type_connectivity=np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 0],\n",
    "                [1, 1, 1, 1, 1],\n",
    "                [1, 1, 0, 0, 0],\n",
    "                [1, 1, 0, 1, 0],\n",
    "                [0, 0, 1, 0, 0],\n",
    "            ]\n",
    "        ),\n",
    "        in_size=[28, 28],\n",
    "        in_channels=1,\n",
    "        out_channels=32,\n",
    "    )\n",
    "]\n",
    "model = SpatiallyEmbeddedRNN(\n",
    "    num_areas=1, area_configs=area_configs, batch_first=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that this is not an exhaustive list, but merely a window into endless possibilities :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter sharing capabilities for $ \\tau_{mem} $\n",
    "\n",
    "We provide the user the option to tie neural time constants:\n",
    "- Across space, but unique for each cell subtype (`tau_mode` = 'subtype')\n",
    "- Across cell subtype, but unique for each spatial location (`tau_mode` = 'spatial')\n",
    "- Each neuron learns its own time constant (`tau_mode` = 'subtype_spatial')\n",
    "- Across ***types*** (`tau_mode` = 'type')\n",
    "\n",
    "To go hand in hand with this, we also allow the user to provide an initialization for these time constants. This can be done via `tau_init_fn`. As with the nonlinearities, users can either provide torch initializers or custom functions to accomplish this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchically constructed neural areas\n",
    "\n",
    "Intuitive and expressive. For reasons more than one, you may want to wire up brain areas that are connected to each other via long-range synapses. This is quite easy to accomplish in `torch-biopl`. Note that each area can be configured independently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "        num_neuron_types=2,\n",
    "        num_neuron_subtypes=np.array([16, 16]),\n",
    "        neuron_type_class=np.array([\"excitatory\", \"inhibitory\"]),\n",
    "        inter_neuron_type_connectivity=np.array(\n",
    "            [[1, 1, 0], [1, 1, 1], [1, 1, 0]]\n",
    "        ),\n",
    "        in_size=[28, 28],\n",
    "        in_channels=1,\n",
    "        out_channels=32,\n",
    "    ),\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "        num_neuron_types=2,\n",
    "        num_neuron_subtypes=np.array([32, 32]),\n",
    "        neuron_type_class=np.array([\"excitatory\", \"inhibitory\"]),\n",
    "        inter_neuron_type_connectivity=np.array(\n",
    "            [[1, 1, 0], [1, 1, 1], [1, 1, 0]]\n",
    "        ),\n",
    "        in_size=[14, 14],\n",
    "        in_channels=32,\n",
    "        out_channels=32,\n",
    "    ),\n",
    "]\n",
    "\n",
    "model = SpatiallyEmbeddedRNN(\n",
    "    num_areas=2, area_configs=area_configs, batch_first=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-areal feedback connectivity\n",
    "\n",
    "Finally, when you have multiple interacting areas, you'd want to ability to feedback information from downstream areas back up to early areas. `torch-biopl` provides an easy way to configure the flow of information. In simple terms, users can provide an adjacency matrix where rows are presynaptic ***areas*** and columns are postsynaptic ***areas***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          neuron_0  neuron_1  output\n",
      "input        False     False   False\n",
      "feedback     False     False   False\n",
      "neuron_0     False     False   False\n",
      "neuron_1     False     False   False\n"
     ]
    }
   ],
   "source": [
    "conn = SpatiallyEmbeddedAreaConfig.inter_neuron_type_connectivity_template_df(\n",
    "    use_feedback=True, num_neuron_types=2\n",
    ")\n",
    "# this prints out the format of the connectivity adjacency matrix that you can follow\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs_feedback_model = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "        num_neuron_types=2,\n",
    "        num_neuron_subtypes=np.array([16, 16]),\n",
    "        neuron_type_class=np.array([\"excitatory\", \"inhibitory\"]),\n",
    "        inter_neuron_type_connectivity=np.array(\n",
    "            [[1, 1, 0], [1, 0, 0], [1, 1, 1], [1, 1, 0]]\n",
    "        ),\n",
    "        feedback_channels=16,\n",
    "        in_size=[28, 28],\n",
    "        in_channels=1,\n",
    "        out_channels=32,\n",
    "    ),\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "        num_neuron_types=2,\n",
    "        num_neuron_subtypes=np.array([32, 32]),\n",
    "        neuron_type_class=np.array([\"excitatory\", \"inhibitory\"]),\n",
    "        inter_neuron_type_connectivity=np.array(\n",
    "            [[1, 1, 0], [1, 1, 1], [1, 1, 0]]\n",
    "        ),\n",
    "        in_size=[14, 14],\n",
    "        in_channels=32,\n",
    "        out_channels=32,\n",
    "    ),\n",
    "]\n",
    "\n",
    "model_wFeedback = SpatiallyEmbeddedRNN(\n",
    "    num_areas=2,\n",
    "    area_configs=area_configs_feedback_model,\n",
    "    batch_first=False,\n",
    "    inter_area_feedback_connectivity=np.array([[0, 0], [1, 0]]),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioplnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
