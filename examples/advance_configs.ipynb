{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring advanced configurations\n",
    "\n",
    "## Overview\n",
    "\n",
    "In addition to the essential capabilities exposed in the first tutorial, we can exercise fine-grained control in how we wire up biologically-plausible networks. These are some of the functionality we will explore in this section:\n",
    "\n",
    "- Synapse vs neuron nonlinearities\n",
    "- Microcircuit archetypes\n",
    "- Parameter sharing capabilities\n",
    "- Hierarchically constructed neural areas\n",
    "- Inter-areal feedback connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from bioplnn.models import SpatiallyEmbeddedRNN, SpatiallyEmbeddedAreaConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synapse vs neuron nonlinearities\n",
    "\n",
    "What do we mean by this? In an attempt to distinguish synaptic transfer functions from post-aggregation neuronal transfer functions, we give users the ability to specify pre- and post-integration nonlinearities. \n",
    "\n",
    "Let us consider the same example model from the previous tutorial: A simple one-area network with two neural classes with the following `inter_cell_type_connectivity`: $\\begin{bmatrix}1&1&0\\cr1&1&1\\cr1&1&0\\end{bmatrix}$. Following the same convention as the connectivity matrix, you can specify the transfer function for each of those synapse groups by setting the `inter_cell_type_nonlinearity` parameter. Similarly, `cell_type_nonlinearity` can be used to control the post-aggregation transfer function for each cell type.\n",
    "\n",
    "If you were to construe a scenario where synapses have unbounded transfer functions while the neuron as whole is bounded from above (and for the sake of argument: bounded differently for the E and I subpopulations), then you'd do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a custom activation function that works similarly to a ReLU but is bounded from above!\n",
    "from torch.nn.modules.activation import Hardtanh\n",
    "class ModRelu(Hardtanh):\n",
    "    def __init__(self, _ub: float, _lb: float = 0., inplace: bool = False):\n",
    "        super().__init__(_lb, _ub, inplace)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        inplace_str = 'inplace=True' if self.inplace else ''\n",
    "        return inplace_str\n",
    "upper_bounded_relu = ModRelu(_ub = 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "                num_cell_types = 2,\n",
    "                num_cell_subtypes = np.array([16, 16]),\n",
    "                cell_type_class = np.array(['excitatory', 'inhibitory']),\n",
    "                cell_type_nonlinearity = ['sigmoid', upper_bounded_relu],\n",
    "                inter_cell_type_connectivity = np.array([[1, 1, 0], [1, 1, 1], [1, 1, 0]]),\n",
    "                inter_cell_type_nonlinearity = np.array([['relu', 'relu', ''], ['relu', 'relu', 'relu'], ['relu', 'relu', '']]),\n",
    "                in_size = [28, 28],\n",
    "                in_channels =  1,\n",
    "                out_channels = 32,\n",
    "    )\n",
    "]\n",
    "model = SpatiallyEmbeddedRNN(num_areas=1, area_configs=area_configs, batch_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microcircuit archetypes\n",
    "\n",
    "It must be evident that `inter_cell_type_connectivity` is a powerful option that can be used to dictate a wide variety of microcircuit motifs. We provide some examples below for inspiration.\n",
    "\n",
    "#### Feedback inhibition\n",
    "Parvalbumin-positive inhibitory cells in Layer 2/3 of the cortex are known to interact with Pyramidal cells through some form of divisive inhibition [Jonke et al. (2017)](https://www.jneurosci.org/content/37/35/8511). To instantiate this microcircuit, you'd set `inter_cell_type_connectivity` $= \\begin{bmatrix}1&0&0\\cr0&1&1\\cr1&1&0\\end{bmatrix}$ (conventions same as in the original example).\n",
    "\n",
    "#### Feedforward inhibition\n",
    "Feedforward inhibition is another essential mechanism within the brain, to regulate neuronal firing and prevent runaway excitation ([Panthi and Leitch (2019)](https://pubmed.ncbi.nlm.nih.gov/31494287/), [Large et al. (2016)](https://pmc.ncbi.nlm.nih.gov/articles/PMC4776521/)). To implement the microcircuit presented in these (and related) papers, you can set `inter_cell_type_connectivity` $= \\begin{bmatrix}1&1&0\\cr1&0&1\\cr1&1&1\\end{bmatrix}$\n",
    "\n",
    "#### Pyr-PV-SST-VIP motif\n",
    "Interneuron subtypes play a critical role in several aspects of cortical function ([Guo and Kumar (2023)](https://www.nature.com/articles/s42003-023-05231-0), [Condylis et al. (2022)](https://www.science.org/doi/10.1126/science.abl5981), etc.). Of particular interest is a motif that involves one excitatory and three inhibitory interneuron populations (PV, SST, VIP). Please refer to these papers for pictorial depictions of the microcircuits. To realise this in `torch-biopl`, we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "                num_cell_types = 4,\n",
    "                num_cell_subtypes = np.array([16, 8, 8, 8]),\n",
    "                cell_type_class = np.array(['excitatory', 'inhibitory', 'inhibitory', 'inhibitory']),\n",
    "                inter_cell_type_connectivity = np.array([[1, 0, 0, 0, 0], [1, 1, 1, 1, 1], [1, 1, 0, 0, 0], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0]]),\n",
    "                in_size = [28, 28],\n",
    "                in_channels =  1,\n",
    "                out_channels = 32,\n",
    "    )\n",
    "]\n",
    "model = SpatiallyEmbeddedRNN(num_areas=1, area_configs=area_configs, batch_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that this is not an exhaustive list, but merely a window into endless possibilities :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter sharing capabilities for $ \\tau_{mem} $\n",
    "\n",
    "We provide the user the option to tie neural time constants:\n",
    "- Across space, but unique for each cell subtype (`tau_mode` = 'subtype')\n",
    "- Across cell subtype, but unique for each spatial location (`tau_mode` = 'spatial')\n",
    "- Each neuron learns its own time constant (`tau_mode` = 'subtype_spatial')\n",
    "- Across ***types*** (`tau_mode` = 'type')\n",
    "\n",
    "To go hand in hand with this, we also allow the user to provide an initialization for these time constants. This can be done via `tau_init_fn`. As with the nonlinearities, users can either provide torch initializers or custom functions to accomplish this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchically constructed neural areas\n",
    "\n",
    "Intuitive and expressive. For reasons more than one, you may want to wire up brain areas that are connected to each other via long-range synapses. This is quite easy to accomplish in `torch-biopl`. Note that each area can be configured independently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_configs = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "                num_cell_types = 2,\n",
    "                num_cell_subtypes = np.array([16, 16]),\n",
    "                cell_type_class = np.array(['excitatory', 'inhibitory']),\n",
    "                inter_cell_type_connectivity = np.array([[1, 1, 0], [1, 1, 1], [1, 1, 0]]),\n",
    "                in_size = [28, 28],\n",
    "                in_channels =  1,\n",
    "                out_channels = 32,\n",
    "    ),\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "                num_cell_types = 2,\n",
    "                num_cell_subtypes = np.array([32, 32]),\n",
    "                cell_type_class = np.array(['excitatory', 'inhibitory']),\n",
    "                inter_cell_type_connectivity = np.array([[1, 1, 0], [1, 1, 1], [1, 1, 0]]),\n",
    "                in_size = [14, 14],\n",
    "                in_channels =  32,\n",
    "                out_channels = 32,\n",
    "    )\n",
    "]\n",
    "\n",
    "model = SpatiallyEmbeddedRNN(num_areas=2, area_configs=area_configs, batch_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-areal feedback connectivity\n",
    "\n",
    "Finally, when you have multiple interacting areas, you'd want to ability to feedback information from downstream areas back up to early areas. `torch-biopl` provides an easy way to configure the flow of information. In simple terms, users can provide an adjacency matrix where rows are presynaptic ***areas*** and columns are postsynaptic ***areas***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          neuron_0  neuron_1  output\n",
      "input        False     False   False\n",
      "feedback     False     False   False\n",
      "neuron_0     False     False   False\n",
      "neuron_1     False     False   False\n"
     ]
    }
   ],
   "source": [
    "conn = SpatiallyEmbeddedAreaConfig.inter_cell_type_connectivity_template_df(use_feedback=True, num_cell_types=2)\n",
    "# this prints out the format of the connectivity adjacency matrix that you can follow\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpatiallyEmbeddedAreaConfig' object has no attribute 'inter_area_feedback_spatial_extents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      1\u001b[39m area_configs_feedback_model = [\n\u001b[32m      2\u001b[39m     SpatiallyEmbeddedAreaConfig(\n\u001b[32m      3\u001b[39m                 num_cell_types = \u001b[32m2\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     )\n\u001b[32m     21\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m model_wFeedback = \u001b[43mSpatiallyEmbeddedRNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mnum_areas\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                            \u001b[49m\u001b[43marea_configs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_configs_feedback_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                            \u001b[49m\u001b[43minter_area_feedback_connectivity\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/vast-storage/scratch/vast/mcdermott/lakshmin/hackathon-test/bioplnn/src/bioplnn/models/spatially_embedded.py:1026\u001b[39m, in \u001b[36mSpatiallyEmbeddedRNN.__init__\u001b[39m\u001b[34m(self, num_areas, area_configs, area_kwargs, common_area_kwargs, inter_area_feedback_connectivity, inter_area_feedback_nonlinearity, inter_area_feedback_spatial_extents, area_time_delay, pool_mode, batch_first)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.areas[j].use_feedback:\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1012\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe connection from area \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to area \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1013\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot valid because area \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not receive \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1014\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfeedback (hint: feedback_channels may not be provided)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1015\u001b[39m     )\n\u001b[32m   1016\u001b[39m \u001b[38;5;28mself\u001b[39m.feedback_convs[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = nn.Sequential(\n\u001b[32m   1017\u001b[39m     nn.Upsample(\n\u001b[32m   1018\u001b[39m         size=area_configs[j].in_size,\n\u001b[32m   1019\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1020\u001b[39m     ),\n\u001b[32m   1021\u001b[39m     nn.Conv2d(\n\u001b[32m   1022\u001b[39m         in_channels=area_configs[i].out_channels,\n\u001b[32m   1023\u001b[39m         out_channels=area_configs[j].feedback_channels,\n\u001b[32m   1024\u001b[39m         kernel_size=\u001b[43marea_configs\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m            \u001b[49m\u001b[43mj\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43minter_area_feedback_spatial_extents\u001b[49m[i, j],\n\u001b[32m   1027\u001b[39m         padding=(\n\u001b[32m   1028\u001b[39m             inter_area_feedback_spatial_extents[i, j][\u001b[32m0\u001b[39m]\n\u001b[32m   1029\u001b[39m             // \u001b[32m2\u001b[39m,\n\u001b[32m   1030\u001b[39m             inter_area_feedback_spatial_extents[i, j][\u001b[32m1\u001b[39m]\n\u001b[32m   1031\u001b[39m             // \u001b[32m2\u001b[39m,\n\u001b[32m   1032\u001b[39m         ),\n\u001b[32m   1033\u001b[39m         bias=area_configs[\n\u001b[32m   1034\u001b[39m             j\n\u001b[32m   1035\u001b[39m         ].default_feedback_state_init_fn,\n\u001b[32m   1036\u001b[39m     ),\n\u001b[32m   1037\u001b[39m     get_activation(inter_area_feedback_nonlinearity[i, j]),\n\u001b[32m   1038\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'SpatiallyEmbeddedAreaConfig' object has no attribute 'inter_area_feedback_spatial_extents'"
     ]
    }
   ],
   "source": [
    "area_configs_feedback_model = [\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "                num_cell_types = 2,\n",
    "                num_cell_subtypes = np.array([16, 16]),\n",
    "                cell_type_class = np.array(['excitatory', 'inhibitory']),\n",
    "                inter_cell_type_connectivity = np.array([[1, 1, 0], [1, 0, 0], [1, 1, 1], [1, 1, 0]]),\n",
    "                feedback_channels = 16,\n",
    "                in_size = [28, 28],\n",
    "                in_channels =  1,\n",
    "                out_channels = 32,\n",
    "    ),\n",
    "    SpatiallyEmbeddedAreaConfig(\n",
    "                num_cell_types = 2,\n",
    "                num_cell_subtypes = np.array([32, 32]),\n",
    "                cell_type_class = np.array(['excitatory', 'inhibitory']),\n",
    "                inter_cell_type_connectivity = np.array([[1, 1, 0], [1, 1, 1], [1, 1, 0]]),\n",
    "                in_size = [14, 14],\n",
    "                in_channels =  32,\n",
    "                out_channels = 32,\n",
    "    )\n",
    "]\n",
    "\n",
    "model_wFeedback = SpatiallyEmbeddedRNN(\n",
    "                            num_areas = 2, \n",
    "                            area_configs = area_configs_feedback_model, \n",
    "                            batch_first = False,\n",
    "                            inter_area_feedback_connectivity = np.array([[0, 0],[1, 0]])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioplnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
