{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rdma/vast-rdma/user/valmiki/bioplnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /om2/user/valmiki/bioplnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
      "Requirement already satisfied: jupyterlab in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.0.8)\n",
      "Requirement already satisfied: ipykernel in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (6.26.0)\n",
      "Requirement already satisfied: numpy in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.26.2)\n",
      "Requirement already satisfied: opencv-python in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.8.1.78)\n",
      "Requirement already satisfied: torch==2.0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: torchvision==0.15.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.15.2)\n",
      "Requirement already satisfied: torchaudio==2.0.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
      "Requirement already satisfied: torchsummary in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.5.1)\n",
      "Requirement already satisfied: scipy in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: pandas in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (3.8.1)\n",
      "Requirement already satisfied: mne in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.5.1)\n",
      "Requirement already satisfied: wandb in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.16.0)\n",
      "Requirement already satisfied: accelerate in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.24.1)\n",
      "Requirement already satisfied: lightning in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (2.1.3)\n",
      "Requirement already satisfied: torch-scatter in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (2.1.2+pt20cu117)\n",
      "Requirement already satisfied: torch-sparse in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (0.6.18+pt20cu117)\n",
      "Requirement already satisfied: torchsparsegradutils in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (0.1.2)\n",
      "Requirement already satisfied: filelock in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: networkx in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: requests in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torchvision==0.15.2->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from torchvision==0.15.2->-r requirements.txt (line 7)) (10.1.0)\n",
      "Requirement already satisfied: setuptools in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 6)) (68.2.2)\n",
      "Requirement already satisfied: wheel in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 6)) (0.41.3)\n",
      "Requirement already satisfied: cmake in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 6)) (3.27.7)\n",
      "Requirement already satisfied: lit in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 6)) (17.0.5)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: jupyter-core in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (5.5.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: packaging in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: tomli in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (6.3.3)\n",
      "Requirement already satisfied: traitlets in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab->-r requirements.txt (line 1)) (5.13.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (8.17.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (8.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 2)) (25.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 11)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 12)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 12)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (3.1.1)\n",
      "Requirement already satisfied: tqdm in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from mne->-r requirements.txt (line 14)) (4.66.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from mne->-r requirements.txt (line 14)) (1.8.0)\n",
      "Requirement already satisfied: decorator in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from mne->-r requirements.txt (line 14)) (5.1.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (3.1.40)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (1.35.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (1.3.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 15)) (4.25.1)\n",
      "Requirement already satisfied: huggingface-hub in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 16)) (0.19.4)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (2023.10.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from lightning->-r requirements.txt (line 17)) (0.10.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from lightning->-r requirements.txt (line 17)) (1.3.0.post0)\n",
      "Requirement already satisfied: pytorch-lightning in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from lightning->-r requirements.txt (line 17)) (2.1.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 15)) (1.16.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (3.9.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 15)) (4.0.11)\n",
      "Requirement already satisfied: jedi>=0.16 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-core->jupyterlab->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: argon2-cffi in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (7.11.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (5.9.2)\n",
      "Requirement already satisfied: overrides in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.6.4)\n",
      "Requirement already satisfied: babel>=2.10 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 1)) (2.13.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 1)) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 1)) (4.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 7)) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from sympy->torch==2.0.1->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->-r requirements.txt (line 17)) (4.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 15)) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 1)) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 1)) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (2.19.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.2.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: webencodings in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (2.4)\n",
      "Requirement already satisfied: uri-template in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: pycparser in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /rdma/vast-rdma/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r requirements.txt (line 1)) (2.8.19.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "import torchsparsegradutils as tsgu\n",
    "import torch_sparse\n",
    "from tqdm import tqdm\n",
    "from bioplnn.topography import TopographicalRNN\n",
    "from bioplnn.utils import AttrDict, get_MNIST_V1_dataloaders, print_mem_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 23 17:37:14 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    60W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    # Model parameters\n",
    "    # num_neurons=100000,\n",
    "    synapses_per_neuron=32,\n",
    "    sheet_size=(256, 256),\n",
    "    connectivity_std=10,\n",
    "    num_timesteps=100,\n",
    "    pool_stride=4,\n",
    "    sheet_bias=True,\n",
    "    sheet_mm_function=\"torch_sparse\",\n",
    "    sheet_batch_first=False,\n",
    "    sheet_sparse_format=\"torch_sparse\",\n",
    "    adjacency_matrix_path=\"connection/sparse.pt\",\n",
    "    model_dir=\"models\",\n",
    "    # Training parameters\n",
    "    batch_size=16,\n",
    "    optimizer=optim.SGD,\n",
    "    lr=1e-3,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    log_freq=50,\n",
    "    num_epochs=30,\n",
    "    log_wandb=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "try:\n",
    "    os.mkdir(config.model_dir)  # type: ignore\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TopographicalRNN(**config).to(device)  # type: ignore\n",
    "    optimizer = config.optimizer(model.parameters(), lr=config.lr)\n",
    "    criterion = config.criterion()\n",
    "    train_loader, test_loader = get_MNIST_V1_dataloaders(config)\n",
    "\n",
    "    if config.log_wandb:\n",
    "        wandb.init(project=\"Cortical RNN\", config=config)\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        bar = tqdm(\n",
    "            train_loader,\n",
    "            desc=(\n",
    "                f\"Training | Epoch: {epoch} | \"\n",
    "                f\"Loss: {0:.4f} | \"\n",
    "                f\"Acc: {0:.2%}\"\n",
    "            ),\n",
    "        )\n",
    "        for i, (images, labels) in enumerate(bar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics\n",
    "            train_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_correct += correct\n",
    "            running_correct += correct\n",
    "            train_total += len(labels)\n",
    "            running_total += len(labels)\n",
    "\n",
    "            # Log statistics\n",
    "            if (i + 1) % config.log_freq == 0:\n",
    "                running_loss /= config.log_freq\n",
    "                running_acc = running_correct / running_total\n",
    "                if config.log_wandb:\n",
    "                    wandb.log(\n",
    "                        dict(\n",
    "                            running_loss=running_loss, running_acc=running_acc\n",
    "                        )\n",
    "                    )\n",
    "                bar.set_description(\n",
    "                    f\"Training | Epoch: {epoch} | \"\n",
    "                    f\"Loss: {running_loss:.4f} | \"\n",
    "                    f\"Acc: {running_acc:.2%}\"\n",
    "                )\n",
    "                running_loss = 0\n",
    "                running_correct = 0\n",
    "                running_total = 0\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        if config.log_wandb:\n",
    "            wandb.log(dict(train_loss=train_loss, train_acc=train_acc))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Update statistics\n",
    "                test_loss += loss.item()\n",
    "                predicted = outputs.argmax(-1)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                test_correct += correct\n",
    "                test_total += len(labels)\n",
    "\n",
    "        # Calculate average test loss and accuracy\n",
    "        test_loss /= len(train_loader)\n",
    "        test_acc = test_correct / test_total\n",
    "\n",
    "        if config.log_wandb:\n",
    "            wandb.log(\n",
    "                dict(test_loss=test_loss, test_acc=test_acc, epoch=epoch)\n",
    "            )\n",
    "\n",
    "        # Print the epoch statistics\n",
    "        print(\n",
    "            f\"Epoch [{epoch}/{config.num_epochs}] | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Train Accuracy: {train_acc:.2%} | \"\n",
    "            f\"Test Loss: {test_loss:.4f}, \"\n",
    "            f\"Test Accuracy: {test_acc:.2%}\"\n",
    "        )\n",
    "\n",
    "        # Save Model\n",
    "        # Save Model\n",
    "        file_path = os.path.abspath(\n",
    "            os.path.join(config.model_dir, f\"model_{epoch}.pt\")\n",
    "        )\n",
    "        link_path = os.path.abspath(os.path.join(config.model_dir, \"model.pt\"))\n",
    "        torch.save(model, file_path)\n",
    "        try:\n",
    "            os.remove(link_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        os.symlink(file_path, link_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 0/3750 [49:45<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/rdma/vast-rdma/user/valmiki/bioplnn/src/bioplnn/topography.py:286\u001b[0m, in \u001b[0;36mTopographicalRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Pass the input through the CorticalSheet layer num_timesteps times\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps):\n\u001b[0;32m--> 286\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcortical_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Transpose back\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheet_batch_first:\n",
      "File \u001b[0;32m/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/rdma/vast-rdma/user/valmiki/bioplnn/src/bioplnn/topography.py:176\u001b[0m, in \u001b[0;36mTopographicalCorticalCell.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Perform sparse matrix multiplication with or without bias\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_sparse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_neurons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmm_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, x)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmm_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, x)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     )\n",
      "File \u001b[0;32m/om2/user/valmiki/miniconda/envs/pytorch-3.10/lib/python3.10/site-packages/torch_sparse/spmm.py:22\u001b[0m, in \u001b[0;36mspmm\u001b[0;34m(index, value, m, n, matrix)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspmm\u001b[39m(index: Tensor, value: Tensor, m: \u001b[38;5;28mint\u001b[39m, n: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      6\u001b[0m          matrix: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Matrix product of sparse matrix with dense matrix.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`Tensor`\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n \u001b[38;5;241m==\u001b[39m matrix\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m index[\u001b[38;5;241m0\u001b[39m], index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     25\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m matrix \u001b[38;5;28;01mif\u001b[39;00m matrix\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m matrix\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "#     train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "autograd::engine::evaluate_function: SparseAddmmBack...         0.41%      30.035ms        62.90%        4.593s       4.176ms       0.000us         0.00%        4.674s       4.249ms          1100  \n",
      "                                              aten::add         0.43%      31.321ms        12.65%     923.936ms     422.081us       0.000us         0.00%        4.071s       1.860ms          2189  \n",
      "                                        aten::_coalesce         7.66%     559.709ms        74.94%        5.473s       1.765ms        2.738s        47.54%        3.778s       1.218ms          3101  \n",
      "                                         aten::coalesce         2.24%     163.622ms        75.06%        5.481s       1.661ms       0.000us         0.00%        3.643s       1.104ms          3301  \n",
      "                                   SparseAddmmBackward0        -0.25%  -18472.000us        59.81%        4.368s       3.971ms       0.000us         0.00%        2.944s       2.676ms          1100  \n",
      "                                            aten::addmm         0.12%       8.537ms        36.14%        2.640s       1.194ms     270.206ms         4.69%        2.455s       1.110ms          2211  \n",
      "                                    aten::_sparse_addmm         0.31%      22.644ms        36.25%        2.647s       1.209ms       0.000us         0.00%        2.445s       1.117ms          2189  \n",
      "                                              aten::cat         0.93%      68.192ms         2.37%     172.948ms      14.162us        1.744s        30.28%        1.749s     143.221us         12212  \n",
      "                                               aten::mm         0.33%      24.343ms        20.85%        1.523s     681.942us     289.475ms         5.03%        1.604s     718.177us          2233  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us        1.311s        22.75%        1.311s       1.191ms          1100  \n",
      "void at::native::apply::coalesceValuesKernel<float, ...         0.00%       0.000us         0.00%       0.000us       0.000us     953.649ms        16.56%     953.649ms     307.629us          3100  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     853.120ms        14.81%     853.120ms      30.494us         27977  \n",
      "                                             aten::add_         0.51%      37.051ms         9.65%     704.766ms      95.821us      72.322ms         1.26%     732.701ms      99.619us          7355  \n",
      "                                Optimizer.step#SGD.step         0.03%       2.324ms         8.71%     636.253ms      57.841ms       0.000us         0.00%     643.967ms      58.542ms            11  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     476.414ms         8.27%     476.414ms     153.682us          3100  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     433.758ms         7.53%     433.758ms     394.325us          1100  \n",
      "                                            aten::copy_         3.20%     233.620ms        36.36%        2.656s     101.532us     292.804ms         5.08%     396.264ms      15.150us         26156  \n",
      "                                              aten::mul         1.30%      94.817ms         5.24%     383.003ms      59.723us      98.787ms         1.71%     360.604ms      56.230us          6413  \n",
      "                                       cudaLaunchKernel         8.18%     597.649ms         8.18%     597.649ms       4.771us     287.856ms         5.00%     343.034ms       2.739us        125263  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     283.597ms         4.92%     283.597ms     263.077us          1078  \n",
      "                                    cudaPeekAtLastError         0.02%       1.481ms         0.02%       1.481ms       0.010us     262.498ms         4.56%     262.498ms       1.837us        142901  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     246.487ms         4.28%     246.487ms       8.810us         27977  \n",
      "void cusparse::load_balancing_kernel<256u, 1u, 0ul, ...         0.00%       0.000us         0.00%       0.000us       0.000us     233.363ms         4.05%     233.363ms     107.689us          2167  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     227.261ms         3.95%     227.261ms      17.816us         12756  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     146.580ms         2.54%     146.580ms      47.284us          3100  \n",
      "                                      aten::sparse_mask         0.22%      16.067ms         3.11%     226.838ms     206.216us       0.000us         0.00%     130.269ms     118.426us          1100  \n",
      "                                                aten::t         0.15%      10.652ms         2.65%     193.533ms      82.601us       0.000us         0.00%     119.961ms      51.200us          2343  \n",
      "                                        aten::transpose         0.37%      27.209ms         2.64%     192.705ms      28.672us       0.000us         0.00%     119.961ms      17.849us          6721  \n",
      "                                            aten::clone         0.42%      30.755ms         2.38%     173.984ms      39.731us       0.000us         0.00%      97.493ms      22.264us          4379  \n",
      "                                        cudaMemcpyAsync         3.84%     280.354ms         3.84%     280.354ms      14.742us      85.842ms         1.49%      85.842ms       4.514us         19018  \n",
      "                                             aten::div_         0.92%      67.153ms         1.37%     100.352ms      16.110us      69.373ms         1.20%      83.979ms      13.482us          6229  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      82.858ms         1.44%      82.858ms      26.728us          3100  \n",
      "                                            aten::index         0.29%      21.151ms         0.50%      36.551ms      33.228us      79.334ms         1.38%      82.312ms      74.829us          1100  \n",
      "                                              aten::sum         0.88%      64.495ms         1.27%      92.934ms      21.949us      72.935ms         1.27%      81.399ms      19.225us          4234  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      79.334ms         1.38%      79.334ms      72.122us          1100  \n",
      "                                          aten::divide_         0.23%      16.954ms         1.49%     108.872ms      17.560us       0.000us         0.00%      74.976ms      12.093us          6200  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      69.373ms         1.20%      69.373ms      11.189us          6200  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      66.179ms         1.15%      66.179ms      21.273us          3111  \n",
      "                                         aten::_to_copy         0.88%      63.986ms        33.57%        2.451s     432.054us       0.000us         0.00%      65.644ms      11.569us          5674  \n",
      "                                               aten::to         1.28%      93.477ms        33.71%        2.462s     239.605us       0.000us         0.00%      62.725ms       6.104us         10276  \n",
      "                                 cudaDeviceGetAttribute         0.01%       1.044ms         0.01%       1.044ms       0.031us      54.685ms         0.95%      54.685ms       1.604us         34100  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us      49.140ms         0.85%      49.140ms       7.926us          6200  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      39.828ms         0.69%      39.828ms      12.848us          3100  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      32.738ms         0.57%      32.738ms       7.478us          4378  \n",
      "                                  cudaStreamSynchronize        52.79%        3.855s        52.79%        3.855s     206.594us      28.062ms         0.49%      30.128ms       1.614us         18662  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      28.807ms         0.50%      28.807ms       9.293us          3100  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      27.464ms         0.48%      27.464ms       4.993us          5500  \n",
      "                                            aten::fill_         0.33%      24.159ms         0.68%      49.720ms       3.447us      22.000ms         0.38%      26.270ms       1.821us         14423  \n",
      "                                            aten::zero_         0.11%       8.353ms         0.57%      41.939ms      12.705us       0.000us         0.00%      22.579ms       6.840us          3301  \n",
      "void convert_CooToCsr_kernel<0>(int const*, int, int...         0.00%       0.000us         0.00%       0.000us       0.000us      15.323ms         0.27%      15.323ms       7.000us          2189  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.303s\n",
      "Self CUDA time total: 5.760s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        aten::_coalesce       -10.96%  -9162002.000us        96.56%       80.749s      26.090ms       70.803s        87.27%       75.788s      24.487ms          3095  \n",
      "                                         aten::coalesce         2.88%        2.406s        96.57%       80.758s      24.509ms       0.000us         0.00%       73.554s      22.323ms          3295  \n",
      "autograd::engine::evaluate_function: SparseAddmmBack...         0.03%      23.145ms        66.66%       55.751s      50.683ms       0.000us         0.00%       55.158s      50.144ms          1100  \n",
      "                                   SparseAddmmBackward0        -1.00%  -837948.000us        66.37%       55.502s      50.456ms       0.000us         0.00%       53.619s      48.744ms          1100  \n",
      "                                            aten::addmm        -1.71%  -1430865.000us        63.72%       53.286s      24.100ms     242.900ms         0.30%       50.326s      22.762ms          2211  \n",
      "                                    aten::_sparse_addmm         0.54%     450.407ms        63.73%       53.296s      24.347ms       0.000us         0.00%       49.928s      22.809ms          2189  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us       43.396s        53.49%       43.396s       1.132ms         38351  \n",
      "                                               aten::mm        -0.47%  -391222.000us        33.20%       27.767s      12.435ms     290.174ms         0.36%       25.227s      11.297ms          2233  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us       13.894s        17.12%       13.894s       4.491ms          3094  \n",
      "void at::native::apply::coalesceValuesKernel<float, ...         0.00%       0.000us         0.00%       0.000us       0.000us        7.337s         9.04%        7.337s       2.371ms          3094  \n",
      "                                              aten::add         0.15%     126.096ms         1.24%        1.036s      32.180us       0.000us         0.00%        3.628s     112.698us         32189  \n",
      "                                                aten::t         0.01%      11.772ms         0.27%     224.322ms      95.741us       0.000us         0.00%        3.054s       1.304ms          2343  \n",
      "                                        aten::transpose         0.01%       7.697ms         0.27%     224.742ms      33.439us       0.000us         0.00%        3.053s     454.308us          6721  \n",
      "                                              aten::mul         0.29%     239.597ms         0.78%     649.332ms      17.835us        2.746s         3.38%        2.931s      80.515us         36407  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us        2.880s         3.55%        2.880s     930.755us          3094  \n",
      "                                            aten::copy_        12.45%       10.409s        13.78%       11.522s     205.250us        2.871s         3.54%        2.875s      51.210us         56138  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us        2.811s         3.46%        2.811s     220.571us         12744  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us        2.732s         3.37%        2.732s     881.467us          3099  \n",
      "                                              aten::sum         0.10%      87.576ms         0.13%     111.902ms      26.448us        2.033s         2.51%        2.033s     480.496us          4231  \n",
      "void at::native::reduce_kernel<256, 2, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us        2.026s         2.50%        2.026s     653.790us          3099  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us        2.023s         2.49%        2.023s      52.762us         38351  \n",
      "                                              aten::cat         0.14%     113.863ms         0.29%     243.746ms      19.960us        1.573s         1.94%        1.573s     128.776us         12212  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us        1.257s         1.55%        1.257s     203.091us          6188  \n",
      "                                            aten::clone         0.02%      16.246ms         0.23%     193.971ms      44.296us       0.000us         0.00%        1.243s     283.864us          4379  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us        1.175s         1.45%        1.175s       1.069ms          1100  \n",
      "                                         aten::_to_copy        -0.31%  -257050.000us        13.67%       11.429s     320.416us       0.000us         0.00%        1.149s      32.216us         35668  \n",
      "                                               aten::to         0.07%      54.880ms        13.72%       11.475s     127.114us       0.000us         0.00%        1.135s      12.578us         90270  \n",
      "                                             aten::add_         0.08%      68.606ms         0.76%     634.924ms      86.467us      69.012ms         0.09%     638.329ms      86.930us          7343  \n",
      "                                Optimizer.step#SGD.step         0.00%       2.517ms         0.67%     557.601ms      50.691ms       0.000us         0.00%     569.502ms      51.773ms            11  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     397.162ms         0.49%     397.162ms     361.056us          1100  \n",
      "                                            aten::fill_         0.07%      61.010ms         0.08%      67.797ms       4.701us     374.601ms         0.46%     374.601ms      25.972us         14423  \n",
      "                                            aten::zero_         0.01%       7.021ms         0.06%      48.847ms      14.798us       0.000us         0.00%     371.207ms     112.453us          3301  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     364.568ms         0.45%     364.568ms     334.773us          1089  \n",
      "                                       aten::zeros_like         0.00%       3.478ms         0.04%      29.460ms      27.052us       0.000us         0.00%     334.429ms     307.097us          1089  \n",
      "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     284.292ms         0.35%     284.292ms     263.722us          1078  \n",
      "                                  cudaStreamSynchronize        94.17%       78.751s        94.18%       78.760s       4.229ms       0.000us         0.00%     212.140ms      11.389us         18626  \n",
      "void cusparse::load_balancing_kernel<256u, 1u, 0ul, ...         0.00%       0.000us         0.00%       0.000us       0.000us     208.112ms         0.26%     208.112ms      96.037us          2167  \n",
      "                                        cudaMemcpyAsync         0.38%     320.970ms         0.41%     339.156ms      17.856us       0.000us         0.00%     128.596ms       6.770us         18994  \n",
      "                                      aten::sparse_mask         0.01%      11.754ms         0.31%     260.102ms     236.456us       0.000us         0.00%      95.810ms      87.100us          1100  \n",
      "                                             aten::div_         0.13%     105.547ms         0.16%     134.672ms      18.365us      63.568ms         0.08%      74.517ms      10.162us          7333  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      63.568ms         0.08%      63.568ms      10.273us          6188  \n",
      "                                          aten::divide_         0.02%      13.867ms         0.16%     130.346ms      21.064us       0.000us         0.00%      58.299ms       9.421us          6188  \n",
      "                                            aten::index         0.04%      34.776ms         0.05%      42.709ms      38.826us      56.994ms         0.07%      56.994ms      51.813us          1100  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      56.994ms         0.07%      56.994ms      51.813us          1100  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      37.414ms         0.05%      37.414ms      12.092us          3094  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      27.974ms         0.03%      27.974ms       6.390us          4378  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      27.866ms         0.03%      27.866ms       9.006us          3094  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      27.444ms         0.03%      27.444ms       4.990us          5500  \n",
      "void convert_CooToCsr_kernel<0>(int const*, int, int...         0.00%       0.000us         0.00%       0.000us       0.000us      15.323ms         0.02%      15.323ms       7.000us          2189  \n",
      "void cusparse::binary_search_partition_kernel<256, 2...         0.00%       0.000us         0.00%       0.000us       0.000us      13.191ms         0.02%      13.191ms       6.026us          2189  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 83.630s\n",
      "Self CUDA time total: 81.134s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "indices = torch.tensor([[0, 1, 2, 3], [0, 1, 2, 3]]).long()\n",
    "values = torch.tensor([1, 2, 3, 4]).float()\n",
    "weight = torch.sparse_coo_tensor(\n",
    "    indices, values, (100000, 100000), check_invariants=True\n",
    ").coalesce()\n",
    "weight = weight.to_sparse_csr()\n",
    "weight = weight.to(device)\n",
    "weight.requires_grad = True\n",
    "B = weight.clone()\n",
    "\n",
    "weight + B\n",
    "(weight + B).sum().backward()\n",
    "print(weight.grad)\n",
    "\n",
    "\n",
    "indices = torch.tensor([[0, 1, 2, 3], [0, 1, 2, 3]]).long()\n",
    "values = torch.tensor([1, 2, 3, 4]).float()\n",
    "weight = torch.sparse_coo_tensor(\n",
    "    indices, values, (100000, 100000), check_invariants=True\n",
    ").coalesce()\n",
    "weight = weight.to(device)\n",
    "# weight = weight.to_sparse_csr()\n",
    "weight.requires_grad = True\n",
    "\n",
    "x = torch.ones(16, 1, 28, 28).to(device)\n",
    "x = x.flatten(1)\n",
    "x = F.pad(x, (0, 100000 - x.shape[1]))\n",
    "out = x.t()\n",
    "for _ in range(100):\n",
    "    out = F.relu(sparse_mm(weight, out))\n",
    "loss = out.sum()\n",
    "loss.backward()\n",
    "weight.grad\n",
    "model = CorticalRNN(**config)\n",
    "optimizer = config.optimizer(model.parameters(), lr=config.lr)\n",
    "train_loader, _ = get_dataloaders(config)\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "for _ in range(10):\n",
    "    x = next(train_iter)[0]\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "    print(model.cortical_sheet.weight.grad._nnz())\n",
    "    optimizer.step()\n",
    "    print(model.cortical_sheet.weight.grad._nnz())\n",
    "model.cortical_sheet.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorticalRNN\n",
      "cortical_sheet.weight 995140\n",
      "cortical_sheet.bias 10000\n",
      "out_block.0.weight 50176\n",
      "out_block.0.bias 64\n",
      "out_block.2.weight 640\n",
      "out_block.2.bias 10\n",
      "Total Parameters: 1056030\n",
      "\n",
      "TopographicalCorticalRNN\n",
      "cortical_sheet.weight 907791\n",
      "cortical_sheet.bias 10000\n",
      "out_block.0.weight 50176\n",
      "out_block.0.bias 64\n",
      "out_block.2.weight 640\n",
      "out_block.2.bias 10\n",
      "Total Parameters: 968681\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(\"CorticalRNN\")\n",
    "model = CorticalRNN(**config)\n",
    "total_params = 0\n",
    "for param in model.named_parameters():\n",
    "    num_params = (\n",
    "        param[1]._nnz()\n",
    "        if param[0] == \"cortical_sheet.weight\"\n",
    "        else param[1].numel()\n",
    "    )\n",
    "    total_params += num_params\n",
    "    print(param[0], num_params)\n",
    "print(f\"Total Parameters: {total_params}\\n\")\n",
    "\n",
    "print(\"TopographicalCorticalRNN\")\n",
    "model = TopographicalCorticalRNN(**config)\n",
    "total_params = 0\n",
    "for param in model.named_parameters():\n",
    "    num_params = (\n",
    "        param[1]._nnz()\n",
    "        if param[0] == \"cortical_sheet.weight\"\n",
    "        else param[1].numel()\n",
    "    )\n",
    "    total_params += num_params\n",
    "    print(param[0], num_params)\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CorticalSheet(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         num_neurons,\n",
    "#         synapses_per_neuron,\n",
    "#         bias=True,\n",
    "#         mm_function=sparse_mm,\n",
    "#         batch_first=False,\n",
    "#         **kwargs\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         # Save the sparse matrix multiplication function\n",
    "#         self.mm_function = mm_function\n",
    "#         self.batch_first = batch_first\n",
    "\n",
    "#         # Create a sparse tensor for the weight matrix\n",
    "#         indices = []\n",
    "\n",
    "#         # Create adjacency matrix with normal distribution randomized weights\n",
    "#         for i in range(num_neurons):\n",
    "#             synapses = torch.randint(0, num_neurons, (synapses_per_neuron,))\n",
    "#             synapse_root = torch.full_like(synapses, i)\n",
    "#             indices.append(torch.stack((synapses, synapse_root)))\n",
    "#         indices = torch.cat(indices, dim=1)\n",
    "#         # Xavier initialization of values (synapses_per_neuron is the fan-in/out)\n",
    "#         values = torch.randn(num_neurons * synapses_per_neuron) * math.sqrt(\n",
    "#             1 / synapses_per_neuron\n",
    "#         )\n",
    "\n",
    "#         coo_matrix = torch.sparse_coo_tensor(\n",
    "#             indices, values, (num_neurons, num_neurons), check_invariants=True\n",
    "#         ).coalesce()\n",
    "#         self.weight = nn.Parameter(coo_matrix)\n",
    "#         self.weight.register_hook(lambda grad: print(grad))\n",
    "#         # csr_matrix = coo_matrix.coalesce().to_sparse_csr()\n",
    "#         # self.weight = nn.Parameter(csr_matrix)\n",
    "\n",
    "#         # Initialize the bias vector\n",
    "#         self.bias = nn.Parameter(torch.zeros(num_neurons, 1)) if bias else None\n",
    "\n",
    "#     def coalesce(self):\n",
    "#         self.weight.data = self.weight.data.coalesce()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         assert self.weight.is_coalesced()\n",
    "#         # x: Dense (strided) tensor of shape (batch_size, num_neurons) if\n",
    "#         # batch_first, otherwise (num_neurons, batch_size)\n",
    "\n",
    "#         # Transpose input if batch_first\n",
    "#         if self.batch_first:\n",
    "#             x = x.t()\n",
    "\n",
    "#         # Perform sparse matrix multiplication with or without bias\n",
    "#         x = (\n",
    "#             self.mm_function(self.weight, x)\n",
    "#             if self.bias is None\n",
    "#             else self.mm_function(self.weight, x)\n",
    "#         )\n",
    "\n",
    "#         # Transpose output back to batch first\n",
    "#         if self.batch_first:\n",
    "#             x = x.t()\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class CorticalRNN(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         num_neurons,\n",
    "#         synapses_per_neuron,\n",
    "#         num_timesteps,\n",
    "#         activation=nn.GELU,\n",
    "#         sheet_bias=True,\n",
    "#         sheet_mm_function=torch.sparse.mm,\n",
    "#         sheet_batch_first=False,\n",
    "#         **kwargs\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.num_neurons = num_neurons\n",
    "#         self.num_timesteps = num_timesteps\n",
    "#         self.activation = activation()\n",
    "#         self.sheet_batch_first = sheet_batch_first\n",
    "\n",
    "#         # Create the CorticalSheet layer\n",
    "#         self.cortical_sheet = CorticalSheet(\n",
    "#             num_neurons,\n",
    "#             synapses_per_neuron,\n",
    "#             sheet_bias,\n",
    "#             sheet_mm_function,\n",
    "#             sheet_batch_first,\n",
    "#         )\n",
    "\n",
    "#         # Create output block\n",
    "#         self.out_block = nn.Sequential(\n",
    "#             nn.Linear(28 * 28, 64), activation(), nn.Linear(64, 10)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: Dense (strided) tensor of shape (batch_size, 1, 32, 32)\n",
    "\n",
    "#         # Coallesce weight matrix\n",
    "#         self.cortical_sheet.coalesce()\n",
    "\n",
    "#         # Flatten spatial and channel dimensions\n",
    "#         x = x.flatten(1)\n",
    "#         # Pad with zeros for rest of neurons\n",
    "#         x = F.pad(x, (0, self.num_neurons - x.shape[1]))\n",
    "\n",
    "#         # To avoid tranposing x before and after every iteration, we tranpose\n",
    "#         # before and after ALL iterations and do not tranpose within forward()\n",
    "#         # of self.cortical_sheet\n",
    "#         if not self.sheet_batch_first:\n",
    "#             x = x.t()\n",
    "\n",
    "#         # Pass the input through the CorticalSheet layer num_timesteps times\n",
    "#         for _ in range(self.num_timesteps):\n",
    "#             x = self.activation(self.cortical_sheet(x))\n",
    "\n",
    "#         # Transpose back\n",
    "#         if not self.sheet_batch_first:\n",
    "#             x = x.t()\n",
    "\n",
    "#         # Extract output from last 28*28 neurons (can be arbitrarily large number of neurons)\n",
    "#         x = x[:, -28 * 28 :]\n",
    "\n",
    "#         # Return classification from out_block\n",
    "#         return self.out_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
